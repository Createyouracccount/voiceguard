"""
VoiceGuard AI - Response Agent
ë³´ì´ìŠ¤í”¼ì‹± ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½ ì „ë¬¸ ì—ì´ì „íŠ¸
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import json

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

from core.llm_manager import llm_manager
from config.settings import (
    scam_config, detection_thresholds, RiskLevel,
    integration_config
)
from monitoring.langsmith_tracker import tracker

logger = logging.getLogger(__name__)

class InterventionStrategy(BaseModel):
    """ê°œì… ì „ëµ"""
    action_type: str = Field(description="ê°œì… ìœ í˜• (warn/block/report)")
    message_to_user: str = Field(description="ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•  ë©”ì‹œì§€")
    confidence: float = Field(description="ì „ëµ ì‹ ë¢°ë„", ge=0.0, le=1.0)
    urgency: str = Field(description="ê¸´ê¸‰ë„ (low/medium/high/critical)")
    
class ReportingInfo(BaseModel):
    """ì‹ ê³  ì •ë³´"""
    should_report: bool = Field(description="ì‹ ê³  í•„ìš” ì—¬ë¶€")
    agencies: List[str] = Field(description="ì‹ ê³ í•  ê¸°ê´€ ëª©ë¡")
    evidence_summary: str = Field(description="ì¦ê±° ìš”ì•½")
    report_template: str = Field(description="ì‹ ê³ ì„œ í…œí”Œë¦¿")

class UserGuidance(BaseModel):
    """ì‚¬ìš©ì ì•ˆë‚´"""
    immediate_actions: List[str] = Field(description="ì¦‰ì‹œ ì·¨í•´ì•¼ í•  í–‰ë™")
    verification_steps: List[str] = Field(description="í™•ì¸ ì ˆì°¨")
    safety_tips: List[str] = Field(description="ì•ˆì „ ìˆ˜ì¹™")
    support_resources: List[str] = Field(description="ì§€ì› ë¦¬ì†ŒìŠ¤")

class ResponseStrategy(BaseModel):
    """ì¢…í•© ëŒ€ì‘ ì „ëµ"""
    intervention: InterventionStrategy
    reporting: ReportingInfo
    guidance: UserGuidance
    follow_up_required: bool = Field(description="í›„ì† ì¡°ì¹˜ í•„ìš” ì—¬ë¶€")
    estimated_prevention_rate: float = Field(description="ì˜ˆìƒ ì˜ˆë°©ë¥ ", ge=0.0, le=1.0)

class ResponseAgent:
    """ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.name = "ResponseAgent"
        self.strategy_parser = PydanticOutputParser(pydantic_object=ResponseStrategy)
        
        # ëŒ€ì‘ í”„ë¡¬í”„íŠ¸
        self.response_prompt = self._build_response_prompt()
        self.emergency_prompt = self._build_emergency_prompt()
        
        # ëŒ€ì‘ í…œí”Œë¦¿
        self.response_templates = self._load_response_templates()
        
        # í†µê³„
        self.stats = {
            "total_responses": 0,
            "successful_interventions": 0,
            "reports_generated": 0
        }
        
        logger.info("Response Agent ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _build_response_prompt(self) -> ChatPromptTemplate:
        """ëŒ€ì‘ ì „ëµ í”„ë¡¬í”„íŠ¸"""
        return ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ ë³´ì´ìŠ¤í”¼ì‹± ëŒ€ì‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
íƒì§€ëœ ìœ„í˜‘ì— ëŒ€í•œ íš¨ê³¼ì ì¸ ëŒ€ì‘ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

## ëŒ€ì‘ ì›ì¹™
1. **ì‚¬ìš©ì ì•ˆì „ ìµœìš°ì„ **: ê¸ˆì „ì , ì •ì‹ ì  í”¼í•´ ë°©ì§€
2. **ëª…í™•í•œ ì§€ì‹œ**: í˜¼ë€ ì—†ëŠ” êµ¬ì²´ì  í–‰ë™ ì§€ì¹¨
3. **ì‹ ì†í•œ ëŒ€ì‘**: ê³¨ë“ íƒ€ì„ ë‚´ ê°œì…
4. **ì¦ê±° ë³´ì¡´**: í–¥í›„ ì‹ ê³ ë¥¼ ìœ„í•œ ê¸°ë¡
5. **ì‹¬ë¦¬ì  ì§€ì›**: íŒ¨ë‹‰ ë°©ì§€ ë° ì•ˆì •í™”

## ëŒ€ì‘ ìˆ˜ì¤€
- **ê²½ê³  (warn)**: ì£¼ì˜ ë©”ì‹œì§€, í™•ì¸ ì ˆì°¨ ì•ˆë‚´
- **ì°¨ë‹¨ (block)**: ì¦‰ì‹œ í†µí™” ì¢…ë£Œ, ë²ˆí˜¸ ì°¨ë‹¨
- **ì‹ ê³  (report)**: ê´€ê³„ ê¸°ê´€ ìë™ ì‹ ê³ 

## ì‚¬ê¸° ìœ í˜•ë³„ íŠ¹í™” ëŒ€ì‘
- ê¸°ê´€ì‚¬ì¹­: ì§ì ‘ í™•ì¸ ê°•ì¡°, ê³µì‹ ì—°ë½ì²˜ ì œê³µ
- ë‚©ì¹˜í˜‘ë°•: 112 ì‹ ê³ , ê°€ì¡± í™•ì¸ ì ˆì°¨
- ëŒ€ì¶œì‚¬ê¸°: ê¸ˆìœµê°ë…ì› í™•ì¸, ì •ì‹ ì ˆì°¨ ì•ˆë‚´
- ëŒ€ë©´í¸ì·¨: ì ˆëŒ€ ë§Œë‚˜ì§€ ë§ ê²ƒ, í˜„ê¸ˆ ê±°ë˜ ê¸ˆì§€

{format_instructions}
"""),
            ("human", """
ë¶„ì„ ê²°ê³¼:
- ìœ„í—˜ë„: {risk_level}
- ìœ„í—˜ ì ìˆ˜: {risk_score}
- ì‚¬ê¸° ìœ í˜•: {scam_type}
- ì£¼ìš” ì¦ê±°: {evidence}
- ê¸´ê¸‰ë„: {urgency}

ì´ ìƒí™©ì— ëŒ€í•œ ìµœì ì˜ ëŒ€ì‘ ì „ëµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.
""")
        ]).partial(format_instructions=self.strategy_parser.get_format_instructions())
    
    def _build_emergency_prompt(self) -> ChatPromptTemplate:
        """ê¸´ê¸‰ ëŒ€ì‘ í”„ë¡¬í”„íŠ¸"""
        return ChatPromptTemplate.from_messages([
            ("system", """
ê¸´ê¸‰ ìƒí™©ì…ë‹ˆë‹¤. ì¦‰ê°ì ì´ê³  ë‹¨í˜¸í•œ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤.

## ê¸´ê¸‰ ëŒ€ì‘ ì§€ì¹¨
1. ì¦‰ì‹œ í†µí™” ì¢…ë£Œ ê¶Œê³ 
2. 112 ë˜ëŠ” ê´€ë ¨ ê¸°ê´€ ì‹ ê³ 
3. ì¶”ê°€ í”¼í•´ ë°©ì§€ ì¡°ì¹˜
4. ëª…í™•í•˜ê³  ê°•ë ¥í•œ ê²½ê³  ë©”ì‹œì§€

í•œêµ­ì–´ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”.
"""),
            ("human", "ê¸´ê¸‰: {situation}\n\nì¦‰ì‹œ ì „ë‹¬í•  ê²½ê³  ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        ])
    
    def _load_response_templates(self) -> Dict[str, Dict[str, str]]:
        """ëŒ€ì‘ í…œí”Œë¦¿ ë¡œë“œ"""
        return {
            "ê¸°ê´€ì‚¬ì¹­": {
                "warning": "âš ï¸ ì£¼ì˜: ê¸ˆìœµê°ë…ì›ì´ë‚˜ ê²€ì°°ì€ ì „í™”ë¡œ ê°œì¸ì •ë³´ë¥¼ ìš”êµ¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "action": "í†µí™”ë¥¼ ëŠê³  í•´ë‹¹ ê¸°ê´€ì— ì§ì ‘ í™•ì¸í•˜ì„¸ìš”.",
                "contact": "ê¸ˆìœµê°ë…ì›: 1332, ê²€ì°°ì²­: 1301"
            },
            "ë‚©ì¹˜í˜‘ë°•": {
                "warning": "ğŸš¨ ìœ„í—˜: ë‚©ì¹˜ í˜‘ë°• ì˜ì‹¬ë©ë‹ˆë‹¤.",
                "action": "ì¦‰ì‹œ 112ì— ì‹ ê³ í•˜ê³  ê°€ì¡±ì—ê²Œ ì§ì ‘ ì—°ë½í•˜ì„¸ìš”.",
                "contact": "ê¸´ê¸‰ì‹ ê³ : 112"
            },
            "ëŒ€ì¶œì‚¬ê¸°": {
                "warning": "âš ï¸ ì£¼ì˜: ì •ì‹ ê¸ˆìœµê¸°ê´€ì€ ì„ ì…ê¸ˆì„ ìš”êµ¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "action": "ê¸ˆìœµê°ë…ì›ì—ì„œ ì •ì‹ ë“±ë¡ëœ ì—…ì²´ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.",
                "contact": "ê¸ˆìœµê°ë…ì›: 1332"
            },
            "ëŒ€ë©´í¸ì·¨": {
                "warning": "ğŸš« ê²½ê³ : í˜„ê¸ˆì„ ë“¤ê³  ë§Œë‚˜ëŠ” ê²ƒì€ ë§¤ìš° ìœ„í—˜í•©ë‹ˆë‹¤.",
                "action": "ì ˆëŒ€ ë§Œë‚˜ì§€ ë§ˆì‹œê³  ê²½ì°°ì— ì‹ ê³ í•˜ì„¸ìš”.",
                "contact": "ê²½ì°°: 112"
            }
        }
    
    @tracker.track_detection
    async def process_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì‘ì—… ì²˜ë¦¬ ë©”ì¸ ë©”ì„œë“œ"""
        
        risk_level = task_data.get("risk_level", "medium")
        risk_score = task_data.get("risk_score", 0.5)
        scam_type = task_data.get("scam_type", "unknown")
        evidence = task_data.get("evidence", [])
        
        start_time = datetime.now()
        
        try:
            # 1. ê¸´ê¸‰ë„ íŒë‹¨
            urgency = self._determine_urgency(risk_score, scam_type)
            
            # 2. ê¸´ê¸‰ ìƒí™© ì²˜ë¦¬
            if urgency == "critical":
                return await self._handle_emergency(task_data)
            
            # 3. ì¼ë°˜ ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½
            strategy = await self._generate_response_strategy(
                risk_level, risk_score, scam_type, evidence, urgency
            )
            
            # 4. ì‚¬ìš©ì ë©”ì‹œì§€ ìƒì„±
            user_message = self._create_user_message(strategy, scam_type)
            
            # 5. ì‹ ê³  í•„ìš”ì‹œ ì‹ ê³ ì„œ ì¤€ë¹„
            if strategy.reporting.should_report:
                report_data = self._prepare_report(task_data, strategy)
            else:
                report_data = None
            
            # 6. í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = (datetime.now() - start_time).total_seconds()
            self._update_stats(strategy)
            
            return {
                "agent": self.name,
                "timestamp": datetime.now().isoformat(),
                "strategy": strategy.dict(),
                "user_message": user_message,
                "report_data": report_data,
                "processing_time": processing_time,
                "action_required": strategy.intervention.action_type,
                "follow_up_required": strategy.follow_up_required
            }
            
        except Exception as e:
            logger.error(f"Response Agent ì‘ì—… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_response(str(e))
    
    def _determine_urgency(self, risk_score: float, scam_type: str) -> str:
        """ê¸´ê¸‰ë„ ê²°ì •"""
        
        # ë‚©ì¹˜í˜‘ë°•ì€ í•­ìƒ ìµœê³  ê¸´ê¸‰ë„
        if scam_type == "ë‚©ì¹˜í˜‘ë°•":
            return "critical"
        
        # ìœ„í—˜ë„ ê¸°ë°˜ ê¸´ê¸‰ë„
        if risk_score >= detection_thresholds.critical_risk:
            return "critical"
        elif risk_score >= detection_thresholds.high_risk:
            return "high"
        elif risk_score >= detection_thresholds.medium_risk:
            return "medium"
        else:
            return "low"
    
    async def _handle_emergency(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸´ê¸‰ ìƒí™© ì²˜ë¦¬"""
        
        scam_type = task_data.get("scam_type", "unknown")
        situation = f"{scam_type} ìœ í˜•ì˜ ê³ ìœ„í—˜ ë³´ì´ìŠ¤í”¼ì‹± íƒì§€"
        
        # ê¸´ê¸‰ ë©”ì‹œì§€ ìƒì„±
        chain = self.emergency_prompt | llm_manager.models["gpt-3.5-turbo"]
        
        try:
            response = await chain.ainvoke({"situation": situation})
            emergency_message = response.content
        except:
            # í´ë°± ë©”ì‹œì§€
            emergency_message = "ğŸš¨ ìœ„í—˜! ì¦‰ì‹œ í†µí™”ë¥¼ ëŠìœ¼ì„¸ìš”! ë³´ì´ìŠ¤í”¼ì‹±ì´ ì˜ì‹¬ë©ë‹ˆë‹¤."
        
        # ê¸´ê¸‰ ëŒ€ì‘ ì „ëµ
        strategy = ResponseStrategy(
            intervention=InterventionStrategy(
                action_type="block",
                message_to_user=emergency_message,
                confidence=0.95,
                urgency="critical"
            ),
            reporting=ReportingInfo(
                should_report=True,
                agencies=["ê²½ì°°ì²­", "ê¸ˆìœµê°ë…ì›"],
                evidence_summary=json.dumps(task_data.get("evidence", []), ensure_ascii=False),
                report_template=self._generate_emergency_report(task_data)
            ),
            guidance=UserGuidance(
                immediate_actions=[
                    "ì¦‰ì‹œ í†µí™”ë¥¼ ëŠìœ¼ì„¸ìš”",
                    "112ì— ì‹ ê³ í•˜ì„¸ìš”",
                    "ê³„ì¢Œ ì´ì²´ë¥¼ ì¤‘ë‹¨í•˜ì„¸ìš”"
                ],
                verification_steps=[],
                safety_tips=["ì ˆëŒ€ ê°œì¸ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”"],
                support_resources=["112", "1332", "118"]
            ),
            follow_up_required=True,
            estimated_prevention_rate=0.9
        )
        
        return {
            "agent": self.name,
            "timestamp": datetime.now().isoformat(),
            "emergency": True,
            "strategy": strategy.dict(),
            "user_message": emergency_message,
            "action_required": "block",
            "processing_time": 0.1  # ê¸´ê¸‰ ì²˜ë¦¬
        }
    
    async def _generate_response_strategy(self,
                                        risk_level: str,
                                        risk_score: float,
                                        scam_type: str,
                                        evidence: List[str],
                                        urgency: str) -> ResponseStrategy:
        """ëŒ€ì‘ ì „ëµ ìƒì„±"""
        
        chain = self.response_prompt | llm_manager.models["gpt-4"] | self.strategy_parser
        
        try:
            strategy = await chain.ainvoke({
                "risk_level": risk_level,
                "risk_score": risk_score,
                "scam_type": scam_type,
                "evidence": ", ".join(evidence[:5]),  # ìƒìœ„ 5ê°œ ì¦ê±°
                "urgency": urgency
            })
            
            return strategy
            
        except Exception as e:
            logger.error(f"ì „ëµ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°± ì „ëµ
            return self._create_fallback_strategy(risk_level, scam_type)
    
    def _create_user_message(self, strategy: ResponseStrategy, scam_type: str) -> str:
        """ì‚¬ìš©ì ë©”ì‹œì§€ ìƒì„±"""
        
        # í…œí”Œë¦¿ ê¸°ë°˜ ë©”ì‹œì§€
        if scam_type in self.response_templates:
            template = self.response_templates[scam_type]
            base_message = f"{template['warning']}\n\n{template['action']}\n\n{template['contact']}"
        else:
            base_message = strategy.intervention.message_to_user
        
        # ì¶”ê°€ ì•ˆë‚´ì‚¬í•­
        if strategy.guidance.immediate_actions:
            base_message += "\n\nğŸ“‹ ì¦‰ì‹œ í–‰ë™ì‚¬í•­:"
            for action in strategy.guidance.immediate_actions[:3]:
                base_message += f"\nâ€¢ {action}"
        
        return base_message
    
    def _prepare_report(self, task_data: Dict[str, Any], 
                       strategy: ResponseStrategy) -> Dict[str, Any]:
        """ì‹ ê³ ì„œ ì¤€ë¹„"""
        
        return {
            "report_id": f"report_{datetime.now().timestamp()}",
            "timestamp": datetime.now().isoformat(),
            "scam_type": task_data.get("scam_type"),
            "risk_score": task_data.get("risk_score"),
            "evidence": task_data.get("evidence", []),
            "agencies": strategy.reporting.agencies,
            "template": strategy.reporting.report_template,
            "status": "prepared"
        }
    
    def _generate_emergency_report(self, task_data: Dict[str, Any]) -> str:
        """ê¸´ê¸‰ ì‹ ê³ ì„œ ìƒì„±"""
        
        return f"""
[ê¸´ê¸‰ ë³´ì´ìŠ¤í”¼ì‹± ì‹ ê³ ]
ë°œìƒì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì‚¬ê¸°ìœ í˜•: {task_data.get('scam_type', 'ë¯¸ìƒ')}
ìœ„í—˜ë„: ë§¤ìš° ë†’ìŒ
ì£¼ìš” ì¦ê±°: {', '.join(task_data.get('evidence', [])[:3])}
"""
    
    def _create_fallback_strategy(self, risk_level: str, scam_type: str) -> ResponseStrategy:
        """í´ë°± ì „ëµ"""
        
        action_type = "block" if risk_level in ["high", "critical"] else "warn"
        
        return ResponseStrategy(
            intervention=InterventionStrategy(
                action_type=action_type,
                message_to_user="ë³´ì´ìŠ¤í”¼ì‹±ì´ ì˜ì‹¬ë©ë‹ˆë‹¤. í†µí™”ë¥¼ ì¤‘ë‹¨í•˜ê³  í™•ì¸í•˜ì„¸ìš”.",
                confidence=0.7,
                urgency=risk_level
            ),
            reporting=ReportingInfo(
                should_report=risk_level in ["high", "critical"],
                agencies=["ê²½ì°°ì²­"],
                evidence_summary="ìë™ ìƒì„± ì‹¤íŒ¨",
                report_template="í‘œì¤€ ì‹ ê³  í…œí”Œë¦¿"
            ),
            guidance=UserGuidance(
                immediate_actions=["í†µí™” ì¤‘ë‹¨", "ë²ˆí˜¸ í™•ì¸", "ê¸°ê´€ ë¬¸ì˜"],
                verification_steps=["ë°œì‹ ë²ˆí˜¸ í™•ì¸", "ë‚´ìš© í™•ì¸"],
                safety_tips=["ê°œì¸ì •ë³´ ë³´í˜¸", "ì†¡ê¸ˆ ì¤‘ë‹¨"],
                support_resources=["112", "1332"]
            ),
            follow_up_required=True,
            estimated_prevention_rate=0.7
        )
    
    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        
        return {
            "agent": self.name,
            "timestamp": datetime.now().isoformat(),
            "error": error_message,
            "action_required": "warn",
            "user_message": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì£¼ì˜í•˜ì‹œê³  ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í†µí™”ëŠ” ì¦‰ì‹œ ëŠìœ¼ì„¸ìš”.",
            "follow_up_required": True
        }
    
    def _update_stats(self, strategy: ResponseStrategy):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        
        self.stats["total_responses"] += 1
        
        if strategy.reporting.should_report:
            self.stats["reports_generated"] += 1
        
        if strategy.intervention.action_type in ["block", "report"]:
            self.stats["successful_interventions"] += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ë°˜í™˜"""
        
        return {
            **self.stats,
            "intervention_rate": (
                self.stats["successful_interventions"] / 
                max(1, self.stats["total_responses"])
            )
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ëŠ” __init__.pyì—ì„œ ìƒì„±ë¨
#!/usr/bin/env python3
"""
VoiceGuard AI ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ë„êµ¬
í˜„ì¬ AIê°€ ì œëŒ€ë¡œ í™œìš©ë˜ê³  ìˆëŠ”ì§€ í™•ì¸
"""

import asyncio
import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

async def check_ai_status():
    """AI ì‹œìŠ¤í…œ ìƒíƒœ ì¢…í•© í™•ì¸"""
    
    print("ğŸ¤– VoiceGuard AI ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
    print("=" * 60)
    
    status_report = {
        "í™˜ê²½ì„¤ì •": False,
        "LLM_Manager": False,
        "Agents": False,
        "LangChain": False,
        "ì‹¤ì œ_AI_ì‚¬ìš©": False
    }
    
    # 1. í™˜ê²½ì„¤ì • í™•ì¸
    print("\nğŸ“‹ 1. í™˜ê²½ì„¤ì • í™•ì¸")
    try:
        google_key = os.getenv('GOOGLE_API_KEY')
        if google_key and len(google_key) > 20:
            print("   âœ… GOOGLE_API_KEY ì„¤ì •ë¨")
            status_report["í™˜ê²½ì„¤ì •"] = True
        else:
            print("   âŒ GOOGLE_API_KEY ëˆ„ë½ ë˜ëŠ” ì˜ëª»ë¨")
    except Exception as e:
        print(f"   âŒ í™˜ê²½ì„¤ì • ì˜¤ë¥˜: {e}")
    
    # 2. LLM Manager í™•ì¸
    print("\nğŸ§  2. LLM Manager ìƒíƒœ")
    try:
        from core.llm_manager import llm_manager
        
        # ëª¨ë¸ ëª©ë¡
        models = llm_manager.get_available_models()
        print(f"   ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {models}")
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        health = await llm_manager.health_check()
        healthy_models = [m for m, status in health.items() if status]
        
        if healthy_models:
            print(f"   âœ… ì—°ê²°ëœ ëª¨ë¸: {healthy_models}")
            status_report["LLM_Manager"] = True
        else:
            print("   âŒ ì—°ê²°ëœ ëª¨ë¸ ì—†ìŒ")
            
        # ì„±ëŠ¥ í†µê³„
        stats = llm_manager.get_performance_stats()
        print(f"   ğŸ“Š ì´ í˜¸ì¶œ: {stats.get('total_calls', 0)}")
        print(f"   ğŸ’° ì´ ë¹„ìš©: ${stats.get('total_cost', 0):.4f}")
        
    except Exception as e:
        print(f"   âŒ LLM Manager ì˜¤ë¥˜: {e}")
    
    # 3. Agents í™•ì¸
    print("\nğŸ¤– 3. Agent ì‹œìŠ¤í…œ ìƒíƒœ")
    try:
        from agents.detection_agent import DetectionAgent
        from agents.analysis_agent import AnalysisAgent
        from agents.response_agent import ResponseAgent
        
        detection_agent = DetectionAgent()
        print("   âœ… DetectionAgent ë¡œë“œë¨")
        
        analysis_agent = AnalysisAgent()
        print("   âœ… AnalysisAgent ë¡œë“œë¨")
        
        response_agent = ResponseAgent()
        print("   âœ… ResponseAgent ë¡œë“œë¨")
        
        status_report["Agents"] = True
        
    except Exception as e:
        print(f"   âŒ Agents ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 4. LangChain í™•ì¸
    print("\nğŸ”— 4. LangChain ì›Œí¬í”Œë¡œìš° ìƒíƒœ")
    try:
        from langchain_workflows.detection_chain import DetectionChain
        
        detection_chain = DetectionChain()
        print("   âœ… DetectionChain ë¡œë“œë¨")
        
        # ì„±ëŠ¥ í†µê³„
        chain_stats = detection_chain.get_performance_stats()
        print(f"   ğŸ“Š ì²´ì¸ ìƒíƒœ: {chain_stats}")
        
        status_report["LangChain"] = True
        
    except Exception as e:
        print(f"   âŒ LangChain ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 5. ì‹¤ì œ AI í…ŒìŠ¤íŠ¸
    print("\nğŸ§ª 5. ì‹¤ì œ AI ë¶„ì„ í…ŒìŠ¤íŠ¸")
    try:
        if status_report["LLM_Manager"]:
            test_text = "ì•ˆë…•í•˜ì„¸ìš”, ê¸ˆìœµê°ë…ì›ì…ë‹ˆë‹¤. ê³„ì¢Œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤."
            
            print(f"   ğŸ“ í…ŒìŠ¤íŠ¸ ì…ë ¥: {test_text}")
            print("   âš¡ AI ë¶„ì„ ì¤‘...")
            
            start_time = asyncio.get_event_loop().time()
            result = await llm_manager.analyze_scam_risk(text=test_text)
            end_time = asyncio.get_event_loop().time()
            
            print(f"   âœ… AI ë¶„ì„ ì™„ë£Œ ({end_time - start_time:.2f}ì´ˆ)")
            print(f"   ğŸ¯ ìœ„í—˜ë„: {result.metadata.get('risk_score', 0):.1%}")
            print(f"   ğŸ§  ì‚¬ìš©ëœ ëª¨ë¸: {result.model_used}")
            print(f"   ğŸ’° ë¹„ìš©: ${result.cost_estimate:.4f}")
            
            status_report["ì‹¤ì œ_AI_ì‚¬ìš©"] = True
        else:
            print("   â­ï¸ LLM Manager ë¬¸ì œë¡œ ê±´ë„ˆëœ€")
            
    except Exception as e:
        print(f"   âŒ AI í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    # 6. í˜„ì¬ ì‚¬ìš© íŒ¨í„´ ë¶„ì„
    print("\nğŸ“ˆ 6. í˜„ì¬ ì‹œìŠ¤í…œ ì‚¬ìš© íŒ¨í„´ ë¶„ì„")
    try:
        from services.conversation_manager_backup import ConversationManager
        
        # ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” í´ë˜ìŠ¤ í™•ì¸
        print("   ğŸ“‹ ConversationManager ë¶„ì„:")
        
        # ì†ŒìŠ¤ ì½”ë“œì—ì„œ AI ì‚¬ìš© íŒ¨í„´ í™•ì¸
        import inspect
        source = inspect.getsource(ConversationManager.__init__)
        
        if "coordinator_agent" in source:
            print("   âœ… CoordinatorAgent í™œìš©ë¨")
        else:
            print("   âŒ CoordinatorAgent í™œìš© ì•ˆë¨")
            
        if "detection_chain" in source:
            print("   âœ… LangChain í™œìš©ë¨")
        else:
            print("   âŒ LangChain í™œìš© ì•ˆë¨")
            
        if "llm_manager.analyze_scam_risk" in source:
            print("   âœ… ì§ì ‘ LLM í˜¸ì¶œ ì‚¬ìš©ë¨")
        else:
            print("   âŒ ì§ì ‘ LLM í˜¸ì¶œë„ ì•ˆë¨")
            
    except Exception as e:
        print(f"   âŒ ì‚¬ìš© íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    # 7. ìµœì¢… ì§„ë‹¨ ë° ê¶Œì¥ì‚¬í•­
    print("\nğŸ¥ 7. ìµœì¢… ì§„ë‹¨")
    print("=" * 40)
    
    total_score = sum(status_report.values())
    max_score = len(status_report)
    
    print(f"ì „ì²´ ìƒíƒœ: {total_score}/{max_score} ({total_score/max_score*100:.1f}%)")
    
    for component, status in status_report.items():
        icon = "âœ…" if status else "âŒ"
        print(f"   {icon} {component}")
    
    print("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
    
    if not status_report["í™˜ê²½ì„¤ì •"]:
        print("   ğŸ”§ .env íŒŒì¼ì— GOOGLE_API_KEY ì„¤ì • í•„ìš”")
    
    if not status_report["ì‹¤ì œ_AI_ì‚¬ìš©"]:
        print("   ğŸ¤– AI ì‹œìŠ¤í…œì´ ì‹¤ì œë¡œ ì‘ë™í•˜ì§€ ì•ŠìŒ")
        print("   ğŸ“‹ Option 1: Enhanced Systemìœ¼ë¡œ êµì²´ (ìœ„ artifact)")
        print("   ğŸ“‹ Option 2: Simplified Systemìœ¼ë¡œ ë‹¨ìˆœí™”")
    
    if status_report["Agents"] and status_report["LangChain"] and not status_report["ì‹¤ì œ_AI_ì‚¬ìš©"]:
        print("   âš ï¸ ê³ ê¸‰ AI ì‹œìŠ¤í…œì´ êµ¬í˜„ë˜ì–´ ìˆì§€ë§Œ í™œìš©ë˜ì§€ ì•ŠìŒ")
        print("   ğŸ’¡ Enhanced Conversation Manager ì ìš© ê¶Œì¥")
    
    if total_score < 3:
        print("   ğŸš¨ ì‹œìŠ¤í…œ ì „ë©´ ì¬êµ¬ì„± í•„ìš”")
    elif total_score < 4:
        print("   âš ï¸ ì¼ë¶€ ê¸°ëŠ¥ ìˆ˜ì • í•„ìš”")
    else:
        print("   âœ… ì‹œìŠ¤í…œ ìƒíƒœ ì–‘í˜¸")

if __name__ == "__main__":
    asyncio.run(check_ai_status())
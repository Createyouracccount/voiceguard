"""
VoiceGuard AI - AI ì‹œìŠ¤í…œ ì™„ì „ í™œìš© ëŒ€í™” ê´€ë¦¬ì
ëª¨ë“  êµ¬í˜„ëœ Agentì™€ LangChainì„ ì‹¤ì œë¡œ ì‚¬ìš©
"""

import asyncio
import logging
import time
from datetime import datetime
from typing import Dict, Any, Optional, List
from enum import Enum

# êµ¬í˜„ëœ ëª¨ë“  AI ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì‹¤ì œ ì‚¬ìš©
from agents.coordinator_agent import CoordinatorAgent, TaskType, TaskPriority
from agents.detection_agent import DetectionAgent
from agents.analysis_agent import AnalysisAgent
from agents.response_agent import ResponseAgent
from langchain_workflows.detection_chain import DetectionChain
from core.llm_manager import llm_manager
from services.tts_service import tts_service
from services.audio_manager import audio_manager

logger = logging.getLogger(__name__)

class ConversationState(Enum):
    IDLE = "idle"
    LISTENING = "listening"
    DETECTING = "detecting"
    ANALYZING = "analyzing"
    RESPONDING = "responding"
    SPEAKING = "speaking"
    ERROR = "error"

class EnhancedConversationManager:
    """AI ì‹œìŠ¤í…œì„ ì™„ì „íˆ í™œìš©í•˜ëŠ” ëŒ€í™” ê´€ë¦¬ì"""
    
    def __init__(self, client_id: str, client_secret: str):
        # 1. ê¸°ë³¸ ì„œë¹„ìŠ¤ë“¤
        self.llm_manager = llm_manager
        self.tts_service = tts_service
        self.audio_manager = audio_manager
        
        # 2. AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í™œì„±í™”
        self.detection_agent = DetectionAgent()
        self.analysis_agent = AnalysisAgent()
        self.response_agent = ResponseAgent()
        
        # 3. ì½”ë””ë„¤ì´í„° ì—ì´ì „íŠ¸ (ë©€í‹°ì—ì´ì „íŠ¸ ì¡°ì •)
        self.coordinator = CoordinatorAgent(
            self.detection_agent,
            self.analysis_agent,
            self.response_agent
        )
        
        # 4. LangChain ì›Œí¬í”Œë¡œìš°
        self.detection_chain = DetectionChain()
        
        # 5. ìƒíƒœ ê´€ë¦¬
        self.state = ConversationState.IDLE
        self.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.is_running = False
        self.stt_queue = asyncio.Queue(maxsize=10)
        
        # 6. AI í™œìš© í†µê³„
        self.ai_stats = {
            'agent_calls': 0,
            'langchain_calls': 0,
            'coordinator_tasks': 0,
            'avg_agent_time': 0.0,
            'detection_accuracy': 0.0,
            'response_quality': 0.0
        }
        
        # 7. ë”ë¯¸ STT (ì‹¤ì œ êµ¬í˜„ ëŒ€ì²´)
        self.stt_service = self._create_dummy_stt(client_id, client_secret)
        
        logger.info("ğŸ¤– Enhanced AI Conversation Manager ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   í™œì„± ì—ì´ì „íŠ¸: Detection, Analysis, Response")
        logger.info(f"   LangChain ì›Œí¬í”Œë¡œìš°: Detection Chain")
        logger.info(f"   ì½”ë””ë„¤ì´í„°: Multi-Agent ì¡°ì • í™œì„±í™”")

    def _create_dummy_stt(self, client_id: str, client_secret: str):
        """ë”ë¯¸ STT ì„œë¹„ìŠ¤"""
        class DummySTT:
            def __init__(self, client_id, client_secret, callback):
                self.callback = callback
                self.is_running = False
            
            def start(self):
                logger.info("ğŸ¤ ë”ë¯¸ STT ì‹œì‘ (ë°ëª¨ ì…ë ¥ ì‹œë®¬ë ˆì´ì…˜)")
                self.is_running = True
                
                # ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥ë“¤
                demo_inputs = [
                    "ì•ˆë…•í•˜ì„¸ìš”, ê¸ˆìœµê°ë…ì›ì…ë‹ˆë‹¤. ê³ ê°ë‹˜ ê³„ì¢Œì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "ì €ëŠ” ê²€ì°°ì²­ ìˆ˜ì‚¬ê´€ì…ë‹ˆë‹¤. ê¸´ê¸‰í•œ ì‚¬ê±´ìœ¼ë¡œ ì—°ë½ë“œë ¸ìŠµë‹ˆë‹¤.",
                    "ì €ê¸ˆë¦¬ ëŒ€ì¶œ ìŠ¹ì¸ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì§€ê¸ˆ ë°”ë¡œ ì•±ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.",
                    "ì•„ë“¤ì´ ì‚¬ê³ ë‚¬ì–´ìš”! ë³‘ì›ë¹„ê°€ ê¸‰íˆ í•„ìš”í•´ìš”!"
                ]
                
                async def simulate():
                    for i, text in enumerate(demo_inputs):
                        if self.is_running:
                            await asyncio.sleep(5)  # 5ì´ˆ ê°„ê²©
                            logger.info(f"ğŸ¤ ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥ {i+1}: {text[:30]}...")
                            self.callback(text)
                
                asyncio.create_task(simulate())
            
            def stop(self):
                self.is_running = False
        
        return DummySTT(client_id, client_secret, self._on_speech_detected)

    def _on_speech_detected(self, text: str):
        """STT ì½œë°± - íì— ì¶”ê°€"""
        if text and text.strip():
            try:
                loop = asyncio.get_running_loop()
                loop.call_soon_threadsafe(self.stt_queue.put_nowait, text.strip())
            except Exception as e:
                logger.error(f"STT ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    async def start_conversation(self):
        """AI ì‹œìŠ¤í…œì„ ì™„ì „ í™œìš©í•œ ëŒ€í™” ì‹œì‘"""
        
        logger.info("ğŸš€ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # 1. ì½”ë””ë„¤ì´í„° ì‹œì‘ (ë©€í‹°ì—ì´ì „íŠ¸ ì¡°ì •)
        await self.coordinator.start()
        logger.info("âœ… ë©€í‹°ì—ì´ì „íŠ¸ ì½”ë””ë„¤ì´í„° í™œì„±í™”")
        
        # 2. ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.audio_manager.initialize_output()
        
        # 3. STT ì‹œì‘
        self.stt_service.start()
        
        self.is_running = True
        logger.info("ğŸ¤– Enhanced AI ëŒ€í™” ì‹œìŠ¤í…œ ì‹œì‘")
        
        # í™˜ì˜ ë©”ì‹œì§€
        await self._speak("ì•ˆë…•í•˜ì„¸ìš”! VoiceGuard AI ê³ ê¸‰ ë¶„ì„ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì €ëŠ” ì—¬ëŸ¬ AI ì—ì´ì „íŠ¸ì™€ LangChainì„ í™œìš©í•˜ì—¬ ì •êµí•œ ë³´ì´ìŠ¤í”¼ì‹± ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")
        
        # ë©”ì¸ ë£¨í”„
        await self._enhanced_conversation_loop()

    async def _enhanced_conversation_loop(self):
        """AI ì™„ì „ í™œìš© ëŒ€í™” ë£¨í”„"""
        
        self._set_state(ConversationState.LISTENING)
        
        while self.is_running:
            try:
                # STT ì…ë ¥ ëŒ€ê¸°
                user_input = await asyncio.wait_for(
                    self.stt_queue.get(), 
                    timeout=2.0
                )
                
                if user_input:
                    await self._process_with_full_ai_pipeline(user_input)
                    
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"AI ëŒ€í™” ë£¨í”„ ì˜¤ë¥˜: {e}")

    async def _process_with_full_ai_pipeline(self, text: str):
        """ì „ì²´ AI íŒŒì´í”„ë¼ì¸ í™œìš© ì²˜ë¦¬"""
        
        start_time = time.time()
        logger.info(f"ğŸ¤– AI íŒŒì´í”„ë¼ì¸ ì‹œì‘: {text[:50]}...")
        
        try:
            # === STAGE 1: ë©€í‹°ì—ì´ì „íŠ¸ ë³‘ë ¬ ë¶„ì„ ===
            self._set_state(ConversationState.DETECTING)
            
            # ì½”ë””ë„¤ì´í„°ì—ê²Œ íƒì§€ ì‘ì—… ì œì¶œ
            detection_task_id = await self.coordinator.submit_task(
                task_type=TaskType.DETECTION,
                data={"text": text, "context": {"session_id": self.session_id}},
                priority=TaskPriority.HIGH
            )
            
            logger.info(f"ğŸ“¡ ì½”ë””ë„¤ì´í„° íƒì§€ ì‘ì—… ì œì¶œ: {detection_task_id}")
            self.ai_stats['coordinator_tasks'] += 1
            
            # === STAGE 2: LangChain ì›Œí¬í”Œë¡œìš° ë³‘ë ¬ ì‹¤í–‰ ===
            langchain_task = asyncio.create_task(
                self._run_langchain_analysis(text)
            )
            
            # === STAGE 3: ê²°ê³¼ ìˆ˜ì§‘ ë° í†µí•© ===
            self._set_state(ConversationState.ANALYZING)
            
            # ì½”ë””ë„¤ì´í„° ê²°ê³¼ ëŒ€ê¸°
            coordinator_result = await self._wait_for_coordinator_result(detection_task_id)
            
            # LangChain ê²°ê³¼ ëŒ€ê¸°
            langchain_result = await langchain_task
            
            # === STAGE 4: ê²°ê³¼ í†µí•© ë° ì‘ë‹µ ìƒì„± ===
            self._set_state(ConversationState.RESPONDING)
            
            final_analysis = await self._integrate_ai_results(
                coordinator_result, 
                langchain_result,
                text
            )
            
            # === STAGE 5: ê³ ê¸‰ ì‘ë‹µ ìƒì„± ===
            response_text = await self._generate_enhanced_response(final_analysis)
            
            # === STAGE 6: ìŒì„± ì¶œë ¥ ===
            if response_text:
                await self._speak(response_text)
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_ai_stats(processing_time, final_analysis)
            
            logger.info(f"ğŸ¯ AI íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {processing_time:.2f}ì´ˆ")
            
        except Exception as e:
            logger.error(f"AI íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
            await self._speak("AI ì‹œìŠ¤í…œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")

    async def _run_langchain_analysis(self, text: str) -> Dict[str, Any]:
        """LangChain ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        
        logger.info("ğŸ”— LangChain ì›Œí¬í”Œë¡œìš° ì‹œì‘")
        
        try:
            # í¬ê´„ì  ì‚¬ê¸° ë¶„ì„ (LangChain)
            langchain_result = await self.detection_chain.analyze_scam_comprehensive(
                text=text,
                context={"session_id": self.session_id}
            )
            
            self.ai_stats['langchain_calls'] += 1
            logger.info("âœ… LangChain ë¶„ì„ ì™„ë£Œ")
            
            return langchain_result
            
        except Exception as e:
            logger.error(f"LangChain ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e), "source": "langchain"}

    async def _wait_for_coordinator_result(self, task_id: str) -> Dict[str, Any]:
        """ì½”ë””ë„¤ì´í„° ê²°ê³¼ ëŒ€ê¸°"""
        
        for attempt in range(30):  # 30ì´ˆ ëŒ€ê¸°
            task_status = self.coordinator.get_task_status(task_id)
            
            if task_status:
                if task_status["status"] == "completed":
                    logger.info("âœ… ì½”ë””ë„¤ì´í„° ë¶„ì„ ì™„ë£Œ")
                    return task_status.get("result", {})
                elif task_status["status"] == "failed":
                    logger.error(f"âŒ ì½”ë””ë„¤ì´í„° ë¶„ì„ ì‹¤íŒ¨: {task_status.get('error')}")
                    return {"error": task_status.get('error'), "source": "coordinator"}
            
            await asyncio.sleep(1)
        
        logger.warning("â° ì½”ë””ë„¤ì´í„° ì‘ì—… íƒ€ì„ì•„ì›ƒ")
        return {"error": "timeout", "source": "coordinator"}

    async def _integrate_ai_results(self, coordinator_result: Dict, langchain_result: Dict, original_text: str) -> Dict[str, Any]:
        """AI ê²°ê³¼ í†µí•© ë¶„ì„"""
        
        logger.info("ğŸ§  AI ê²°ê³¼ í†µí•© ì¤‘...")
        
        # ê²°ê³¼ ìˆ˜ì§‘
        results = []
        
        if "error" not in coordinator_result:
            results.append({
                "source": "multi_agent_coordinator",
                "data": coordinator_result,
                "weight": 0.6  # ë©€í‹°ì—ì´ì „íŠ¸ì— ë†’ì€ ê°€ì¤‘ì¹˜
            })
        
        if "error" not in langchain_result:
            results.append({
                "source": "langchain_workflow", 
                "data": langchain_result,
                "weight": 0.4  # LangChainì— ë³´ì¡° ê°€ì¤‘ì¹˜
            })
        
        if not results:
            logger.warning("ëª¨ë“  AI ì‹œìŠ¤í…œ ì‹¤íŒ¨ - í´ë°± ë¶„ì„ ì‚¬ìš©")
            return await self._fallback_analysis(original_text)
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ìœ„í—˜ë„ ê³„ì‚°
        total_weight = sum(r["weight"] for r in results)
        weighted_risk = 0.0
        
        all_indicators = set()
        scam_types = []
        
        for result in results:
            data = result["data"]
            weight = result["weight"]
            
            # ìœ„í—˜ë„ ì¶”ì¶œ
            risk_score = self._extract_risk_score(data)
            weighted_risk += risk_score * weight
            
            # ì§€í‘œ ìˆ˜ì§‘
            indicators = self._extract_indicators(data)
            all_indicators.update(indicators)
            
            # ì‚¬ê¸° ìœ í˜• ìˆ˜ì§‘
            scam_type = self._extract_scam_type(data)
            if scam_type:
                scam_types.append(scam_type)
        
        final_risk = weighted_risk / total_weight
        
        return {
            "final_risk_score": final_risk,
            "risk_level": self._determine_risk_level(final_risk),
            "primary_scam_type": scam_types[0] if scam_types else "unknown",
            "all_indicators": list(all_indicators),
            "ai_sources": [r["source"] for r in results],
            "analysis_quality": len(results) / 2.0,  # ë‘ ì‹œìŠ¤í…œ ëª¨ë‘ ì„±ê³µí•˜ë©´ 1.0
            "processing_details": {
                "coordinator_used": any(r["source"] == "multi_agent_coordinator" for r in results),
                "langchain_used": any(r["source"] == "langchain_workflow" for r in results),
                "integration_method": "weighted_ensemble"
            }
        }

    def _extract_risk_score(self, data: Dict) -> float:
        """ë°ì´í„°ì—ì„œ ìœ„í—˜ë„ ì ìˆ˜ ì¶”ì¶œ"""
        return (
            data.get("risk_score", 0.0) or
            data.get("final_risk_score", 0.0) or
            data.get("score", 0.0) or
            0.5  # ê¸°ë³¸ê°’
        )

    def _extract_indicators(self, data: Dict) -> List[str]:
        """ë°ì´í„°ì—ì„œ ìœ„í—˜ ì§€í‘œ ì¶”ì¶œ"""
        return (
            data.get("key_indicators", []) or
            data.get("all_indicators", []) or
            data.get("indicators", []) or
            data.get("detected_patterns", []) or
            []
        )

    def _extract_scam_type(self, data: Dict) -> Optional[str]:
        """ë°ì´í„°ì—ì„œ ì‚¬ê¸° ìœ í˜• ì¶”ì¶œ"""
        return (
            data.get("scam_type") or
            data.get("primary_scam_type") or
            data.get("type") or
            data.get("category")
        )

    def _determine_risk_level(self, risk_score: float) -> str:
        """ìœ„í—˜ë„ ë ˆë²¨ ê²°ì •"""
        if risk_score >= 0.8:
            return "critical"
        elif risk_score >= 0.6:
            return "high"
        elif risk_score >= 0.4:
            return "medium"
        else:
            return "low"

    async def _fallback_analysis(self, text: str) -> Dict[str, Any]:
        """í´ë°± ë¶„ì„ (ëª¨ë“  AI ì‹œìŠ¤í…œ ì‹¤íŒ¨ ì‹œ)"""
        
        logger.info("ğŸ”„ í´ë°± ë¶„ì„ ì‹¤í–‰")
        
        # ê¸°ë³¸ LLM ì§ì ‘ í˜¸ì¶œ
        try:
            result = await self.llm_manager.analyze_scam_risk(text=text)
            
            return {
                "final_risk_score": result.metadata.get("risk_score", 0.5),
                "risk_level": "medium",
                "primary_scam_type": result.metadata.get("scam_type", "unknown"),
                "all_indicators": ["í´ë°±_ë¶„ì„"],
                "ai_sources": ["direct_llm"],
                "analysis_quality": 0.3,
                "processing_details": {
                    "fallback_used": True,
                    "reason": "ai_systems_failed"
                }
            }
        except Exception as e:
            logger.error(f"í´ë°± ë¶„ì„ë„ ì‹¤íŒ¨: {e}")
            return {
                "final_risk_score": 0.5,
                "risk_level": "unknown",
                "primary_scam_type": "analysis_failed",
                "all_indicators": ["ì‹œìŠ¤í…œ_ì˜¤ë¥˜"],
                "ai_sources": [],
                "analysis_quality": 0.0,
                "processing_details": {"total_failure": True}
            }

    async def _generate_enhanced_response(self, analysis: Dict[str, Any]) -> str:
        """AI ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ê³ ê¸‰ ì‘ë‹µ ìƒì„±"""
        
        risk_score = analysis["final_risk_score"]
        risk_level = analysis["risk_level"]
        scam_type = analysis["primary_scam_type"]
        indicators = analysis["all_indicators"]
        ai_sources = analysis["ai_sources"]
        quality = analysis["analysis_quality"]
        
        # AI ì‹œìŠ¤í…œ í™œìš©ë„ í‘œì‹œ
        ai_info = []
        if "multi_agent_coordinator" in ai_sources:
            ai_info.append("ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ")
        if "langchain_workflow" in ai_sources:
            ai_info.append("LangChain ì›Œí¬í”Œë¡œìš°")
        if "direct_llm" in ai_sources:
            ai_info.append("Gemini ì§ì ‘ ë¶„ì„")
        
        response = f"""ğŸ¤– AI ì¢…í•© ë¶„ì„ ê²°ê³¼ (í™œìš© ì‹œìŠ¤í…œ: {', '.join(ai_info)})

ğŸ“Š ìœ„í—˜ë„ í‰ê°€:
â€¢ ìµœì¢… ìœ„í—˜ë„: {risk_score:.1%} ({risk_level})
â€¢ ì¶”ì • ì‚¬ê¸° ìœ í˜•: {scam_type}
â€¢ ë¶„ì„ í’ˆì§ˆ: {quality:.1%}

ğŸ” íƒì§€ëœ ìœ„í—˜ ìš”ì†Œ:
{chr(10).join(f'â€¢ {indicator}' for indicator in indicators[:5])}

ğŸ’¡ AI ë¶„ì„ ìƒì„¸:
â€¢ ì‚¬ìš©ëœ AI ì‹œìŠ¤í…œ: {len(ai_sources)}ê°œ
â€¢ ë¶„ì„ ë°©ë²•: {analysis['processing_details'].get('integration_method', 'ë‹¨ì¼ ë¶„ì„')}"""

        # ìœ„í—˜ë„ë³„ ê¶Œì¥ì‚¬í•­
        if risk_level == "critical":
            response += """

ğŸš¨ ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”:
1. ì§€ê¸ˆ ë‹¹ì¥ í†µí™”ë¥¼ ëŠìœ¼ì„¸ìš”
2. ì ˆëŒ€ ê°œì¸ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”  
3. 112(ê²½ì°°) ë˜ëŠ” 1332(ê¸ˆìœµê°ë…ì›)ì— ì‹ ê³ í•˜ì„¸ìš”
4. ê°€ì¡±ì—ê²Œ ìƒí™©ì„ ì•Œë¦¬ì„¸ìš”"""

        elif risk_level == "high":
            response += """

âš ï¸ ë†’ì€ ìœ„í—˜ ê°ì§€:
1. í†µí™”ë¥¼ ì¤‘ë‹¨í•˜ê³  ì§ì ‘ ê¸°ê´€ì— í™•ì¸í•˜ì„¸ìš”
2. ê¸‰í•˜ê²Œ ê²°ì •í•˜ì§€ ë§ˆì„¸ìš”
3. ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ìš”êµ¬ëŠ” ê±°ì ˆí•˜ì„¸ìš”"""

        elif risk_level == "medium":
            response += """

ğŸ” ì£¼ì˜ í•„ìš”:
1. ìƒëŒ€ë°© ì‹ ì›ì„ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì„¸ìš”
2. ê°œì¸ì •ë³´ ì œê³µ ì „ ì‹ ì¤‘íˆ íŒë‹¨í•˜ì„¸ìš”
3. ì˜ì‹¬ë˜ë©´ ê³µì‹ ê²½ë¡œë¡œ í™•ì¸í•˜ì„¸ìš”"""

        else:
            response += """

âœ… ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì „:
1. ì—¬ì „íˆ ê°œì¸ì •ë³´ëŠ” ì‹ ì¤‘í•˜ê²Œ ì œê³µí•˜ì„¸ìš”
2. ì´ìƒí•œ ìš”êµ¬ê°€ ìˆë‹¤ë©´ ì¦‰ì‹œ í™•ì¸í•˜ì„¸ìš”"""

        return response

    async def _speak(self, text: str):
        """TTS ìŒì„± ì¶œë ¥"""
        self._set_state(ConversationState.SPEAKING)
        
        try:
            audio_stream = self.tts_service.text_to_speech_stream(text)
            await self.audio_manager.play_audio_stream(audio_stream)
        except Exception as e:
            logger.error(f"TTS ì˜¤ë¥˜: {e}")
        
        self._set_state(ConversationState.LISTENING)

    def _set_state(self, new_state: ConversationState):
        """ìƒíƒœ ë³€ê²½"""
        if self.state != new_state:
            old_state = self.state
            self.state = new_state
            logger.debug(f"ìƒíƒœ ë³€ê²½: {old_state.value} -> {new_state.value}")

    def _update_ai_stats(self, processing_time: float, analysis: Dict[str, Any]):
        """AI í†µê³„ ì—…ë°ì´íŠ¸"""
        
        self.ai_stats['agent_calls'] += 1
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„
        current_avg = self.ai_stats['avg_agent_time']
        call_count = self.ai_stats['agent_calls']
        self.ai_stats['avg_agent_time'] = (current_avg * (call_count - 1) + processing_time) / call_count
        
        # ë¶„ì„ í’ˆì§ˆ
        quality = analysis.get('analysis_quality', 0.5)
        self.ai_stats['response_quality'] = (self.ai_stats['response_quality'] + quality) / 2
        
        logger.info(f"ğŸ“ˆ AI ì„±ëŠ¥: ì²˜ë¦¬ì‹œê°„ {processing_time:.2f}ì´ˆ, í’ˆì§ˆ {quality:.1%}")

    def get_ai_status(self) -> Dict[str, Any]:
        """AI ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        
        return {
            "ai_systems_active": {
                "coordinator": hasattr(self, 'coordinator'),
                "detection_agent": hasattr(self, 'detection_agent'),
                "analysis_agent": hasattr(self, 'analysis_agent'),
                "response_agent": hasattr(self, 'response_agent'),
                "langchain_detection": hasattr(self, 'detection_chain'),
                "llm_manager": hasattr(self, 'llm_manager')
            },
            "performance_stats": self.ai_stats.copy(),
            "session_info": {
                "session_id": self.session_id,
                "state": self.state.value,
                "is_running": self.is_running
            }
        }

    async def cleanup(self):
        """ì‹œìŠ¤í…œ ì •ë¦¬"""
        logger.info("ğŸ§¹ Enhanced AI ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...")
        
        self.is_running = False
        
        try:
            if hasattr(self, 'coordinator'):
                await self.coordinator.stop()
            
            if hasattr(self, 'stt_service'):
                self.stt_service.stop()
            
            if hasattr(self, 'audio_manager'):
                self.audio_manager.cleanup()
            
            # ìµœì¢… AI í†µê³„ ì¶œë ¥
            stats = self.get_ai_status()
            logger.info("ğŸ¤– AI ì‹œìŠ¤í…œ ìµœì¢… í†µê³„:")
            logger.info(f"   ì—ì´ì „íŠ¸ í˜¸ì¶œ: {stats['performance_stats']['agent_calls']}")
            logger.info(f"   LangChain í˜¸ì¶œ: {stats['performance_stats']['langchain_calls']}")  
            logger.info(f"   ì½”ë””ë„¤ì´í„° ì‘ì—…: {stats['performance_stats']['coordinator_tasks']}")
            logger.info(f"   í‰ê·  ì²˜ë¦¬ì‹œê°„: {stats['performance_stats']['avg_agent_time']:.2f}ì´ˆ")
            
            logger.info("âœ… Enhanced AI ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
import asyncio
import io
import logging
import time
import hashlib
from typing import AsyncGenerator, Optional, Dict, Any
from concurrent.futures import ThreadPoolExecutor
from elevenlabs import ElevenLabs, AsyncElevenLabs
from config.settings import settings

logger = logging.getLogger(__name__)

class OptimizedTTSService:
    """
    ìµœì í™”ëœ ElevenLabs TTS ì„œë¹„ìŠ¤
    - ì‘ë‹µ ì†ë„ ìµœì í™”
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ 
    - ìºì‹± ì‹œìŠ¤í…œ
    - ì—ëŸ¬ ë³µêµ¬ ê°•í™”
    - ì ì‘í˜• í’ˆì§ˆ ì¡°ì •
    """
    
    def __init__(self):
        # API í‚¤ í™•ì¸
        if not settings.ELEVENLABS_API_KEY:
            logger.warning("ElevenLabs API key not found. TTS will be disabled.")
            self.client = None
            self.async_client = None
            self.is_enabled = False
        else:
            self.client = ElevenLabs(api_key=settings.ELEVENLABS_API_KEY)
            self.async_client = AsyncElevenLabs(api_key=settings.ELEVENLABS_API_KEY)
            self.is_enabled = True
        
        # ìµœì í™”ëœ ìŒì„± ì„¤ì •
        self.voice_config = {
            'voice_id': settings.TTS_VOICE_ID,
            'model': settings.TTS_MODEL,
            'output_format': 'mp3_44100_128',  # ìµœì í™”ëœ í¬ë§·
            'optimize_latency': settings.TTS_OPTIMIZE_LATENCY
        }
        
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        self.performance_config = {
            'max_chunk_size': 500,      # ìµœëŒ€ í…ìŠ¤íŠ¸ ì²­í¬ í¬ê¸°
            'stream_chunk_size': 4096,  # ìŠ¤íŠ¸ë¦¼ ì²­í¬ í¬ê¸°
            'timeout': 10.0,            # ìš”ì²­ íƒ€ì„ì•„ì›ƒ
            'max_retries': 2,           # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            'cache_ttl': 3600,          # ìºì‹œ TTL (1ì‹œê°„)
            'max_cache_size': 50        # ìµœëŒ€ ìºì‹œ í•­ëª© ìˆ˜
        }
        
        # ìºì‹± ì‹œìŠ¤í…œ
        self.response_cache = {}
        self.cache_stats = {'hits': 0, 'misses': 0}
        
        # ìŠ¤ë ˆë“œ í’€ (ë¹„ë™ê¸° ì²˜ë¦¬ìš©)
        self.thread_pool = ThreadPoolExecutor(
            max_workers=3, 
            thread_name_prefix="TTS"
        )
        
        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'avg_response_time': 0.0,
            'cache_hit_rate': 0.0,
            'total_characters': 0
        }
        
        # ì‘ë‹µ ì‹œê°„ ì¶”ì 
        self.response_times = []
        self.max_response_history = 20
        
    async def text_to_speech_stream(self, text: str) -> AsyncGenerator[bytes, None]:
        """
        ìµœì í™”ëœ ì‹¤ì‹œê°„ TTS ìŠ¤íŠ¸ë¦¬ë°
        - ìºì‹± í™œìš©
        - ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
        - ì˜¤ë¥˜ ë³µêµ¬
        """
        
        if not self.is_enabled:
            logger.error("TTS ì„œë¹„ìŠ¤ê°€ ë¹„í™œì„±í™”ë¨")
            yield b''
            return
        
        start_time = time.time()
        self.stats['total_requests'] += 1
        
        try:
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            processed_text = self._preprocess_text(text)
            
            # ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(processed_text)
            cached_result = self._get_from_cache(cache_key)
            
            if cached_result:
                self.cache_stats['hits'] += 1
                logger.debug(f"ìºì‹œ íˆíŠ¸: {processed_text[:30]}...")
                
                # ìºì‹œëœ ë°ì´í„°ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ yield
                async for chunk in self._stream_cached_data(cached_result):
                    yield chunk
                
                self._update_success_stats(start_time)
                return
            
            self.cache_stats['misses'] += 1
            
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ë¶„í•  ì²˜ë¦¬
            if len(processed_text) > self.performance_config['max_chunk_size']:
                async for chunk in self._process_long_text(processed_text, cache_key):
                    yield chunk
            else:
                async for chunk in self._process_short_text(processed_text, cache_key):
                    yield chunk
            
            self._update_success_stats(start_time)
            
        except Exception as e:
            logger.error(f"TTS ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
            self.stats['failed_requests'] += 1
            
            # í´ë°± ì²˜ë¦¬
            async for chunk in self._handle_tts_error(text):
                yield chunk
    
    async def _process_short_text(self, text: str, cache_key: str) -> AsyncGenerator[bytes, None]:
        """ì§§ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        
        try:
            # ElevenLabs API í˜¸ì¶œ (ë¹„ë™ê¸° ìµœì í™”)
            audio_data = await self._call_elevenlabs_api(text)
            
            if audio_data:
                # ìºì‹œì— ì €ì¥
                self._save_to_cache(cache_key, audio_data)
                
                # ì²­í¬ ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
                async for chunk in self._stream_audio_data(audio_data):
                    yield chunk
            else:
                logger.warning("TTS APIë¡œë¶€í„° ë¹ˆ ì‘ë‹µ")
                yield b''
                
        except Exception as e:
            logger.error(f"ì§§ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            yield b''
    
    async def _process_long_text(self, text: str, base_cache_key: str) -> AsyncGenerator[bytes, None]:
        """ê¸´ í…ìŠ¤íŠ¸ ë¶„í•  ì²˜ë¦¬"""
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
        sentences = self._split_text_intelligently(text)
        
        for i, sentence in enumerate(sentences):
            if not sentence.strip():
                continue
            
            try:
                # ê° ë¬¸ì¥ë³„ ìºì‹œ í‚¤
                sentence_cache_key = f"{base_cache_key}_part_{i}"
                
                # ìºì‹œ í™•ì¸
                cached_audio = self._get_from_cache(sentence_cache_key)
                
                if cached_audio:
                    async for chunk in self._stream_cached_data(cached_audio):
                        yield chunk
                else:
                    # API í˜¸ì¶œ
                    audio_data = await self._call_elevenlabs_api(sentence.strip())
                    
                    if audio_data:
                        self._save_to_cache(sentence_cache_key, audio_data)
                        async for chunk in self._stream_audio_data(audio_data):
                            yield chunk
                
                # ë¬¸ì¥ ê°„ ì§§ì€ íœ´ì‹ (ìì—°ìŠ¤ëŸ¬ìš´ ë°œìŒ)
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.error(f"ë¬¸ì¥ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
    
    async def _call_elevenlabs_api(self, text: str) -> bytes:
        """ElevenLabs API í˜¸ì¶œ (ìµœì í™”)"""
        
        def sync_api_call():
            """ë™ê¸° API í˜¸ì¶œ (ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)"""
            try:
                # stream ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ (ë” ë¹ ë¦„)
                audio_stream = self.client.text_to_speech.stream(
                    text=text,
                    voice_id=self.voice_config['voice_id'],
                    model_id=self.voice_config['model'],
                    output_format=self.voice_config['output_format']
                )
                
                # ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ìˆ˜ì§‘
                chunks = []
                for chunk in audio_stream:
                    if isinstance(chunk, bytes):
                        chunks.append(chunk)
                
                return b''.join(chunks)
                
            except Exception as e:
                logger.warning(f"stream í˜¸ì¶œ ì‹¤íŒ¨, convertë¡œ í´ë°±: {e}")
                
                # convert ë°©ì‹ìœ¼ë¡œ í´ë°±
                try:
                    audio_generator = self.client.text_to_speech.convert(
                        text=text,
                        voice_id=self.voice_config['voice_id'],
                        model_id=self.voice_config['model'],
                        output_format=self.voice_config['output_format']
                    )
                    
                    chunks = []
                    for chunk in audio_generator:
                        if isinstance(chunk, bytes):
                            chunks.append(chunk)
                    
                    return b''.join(chunks)
                    
                except Exception as fallback_error:
                    logger.error(f"convert í´ë°±ë„ ì‹¤íŒ¨: {fallback_error}")
                    return b''
        
        # ìŠ¤ë ˆë“œ í’€ì—ì„œ ë¹„ë™ê¸° ì‹¤í–‰
        try:
            audio_data = await asyncio.wait_for(
                asyncio.to_thread(sync_api_call),
                timeout=self.performance_config['timeout']
            )
            
            self.stats['total_characters'] += len(text)
            return audio_data
            
        except asyncio.TimeoutError:
            logger.error(f"TTS API íƒ€ì„ì•„ì›ƒ: {text[:50]}...")
            return b''
        except Exception as e:
            logger.error(f"TTS API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return b''
    
    async def _stream_audio_data(self, audio_data: bytes) -> AsyncGenerator[bytes, None]:
        """ì˜¤ë””ì˜¤ ë°ì´í„° ì²­í¬ ìŠ¤íŠ¸ë¦¬ë°"""
        
        chunk_size = self.performance_config['stream_chunk_size']
        
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i + chunk_size]
            if chunk:
                yield chunk
                # ìŠ¤íŠ¸ë¦¬ë° ì§€ì—° ìµœì†Œí™”
                await asyncio.sleep(0.001)
    
    async def _stream_cached_data(self, cached_data: bytes) -> AsyncGenerator[bytes, None]:
        """ìºì‹œëœ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°"""
        async for chunk in self._stream_audio_data(cached_data):
            yield chunk
    
    async def _handle_tts_error(self, original_text: str) -> AsyncGenerator[bytes, None]:
        """TTS ì˜¤ë¥˜ ì²˜ë¦¬"""
        
        logger.info("TTS ì˜¤ë¥˜ - ë¹ˆ ì‘ë‹µ ë°˜í™˜")
        yield b''
    
    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        
        # ê¸°ë³¸ ì •ë¦¬
        processed = text.strip()
        
        # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ ìë¥´ê¸°
        max_length = 1000
        if len(processed) > max_length:
            # ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸°
            sentences = processed.split('.')
            truncated = []
            current_length = 0
            
            for sentence in sentences:
                if current_length + len(sentence) > max_length:
                    break
                truncated.append(sentence)
                current_length += len(sentence)
            
            processed = '.'.join(truncated)
            if not processed.endswith('.'):
                processed += '.'
        
        # íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬
        processed = processed.replace('ğŸš¨', 'ê¸´ê¸‰:')
        processed = processed.replace('âš ï¸', 'ì£¼ì˜:')
        processed = processed.replace('âœ…', 'ì™„ë£Œ:')
        processed = processed.replace('ğŸ“', 'ì—°ë½ì²˜:')
        
        return processed
    
    def _split_text_intelligently(self, text: str) -> list:
        """ì§€ëŠ¥ì  í…ìŠ¤íŠ¸ ë¶„í• """
        
        # ë¬¸ì¥ ë¶„í•  ìš°ì„ ìˆœìœ„
        splitters = ['. ', '! ', '? ', '\n', ':', ';']
        
        sentences = [text]
        
        for splitter in splitters:
            new_sentences = []
            for sentence in sentences:
                if splitter in sentence:
                    parts = sentence.split(splitter)
                    for i, part in enumerate(parts):
                        if part.strip():
                            if i < len(parts) - 1:
                                new_sentences.append(part + splitter.strip())
                            else:
                                new_sentences.append(part)
                else:
                    new_sentences.append(sentence)
            sentences = new_sentences
        
        # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ë“¤ í•©ì¹˜ê¸°
        final_sentences = []
        current_group = []
        
        for sentence in sentences:
            current_group.append(sentence)
            
            # 50ì ì´ìƒì´ê±°ë‚˜ ë§ˆì§€ë§‰ ë¬¸ì¥ì´ë©´ ê·¸ë£¹ ì™„ì„±
            if (sum(len(s) for s in current_group) >= 50 or 
                sentence == sentences[-1]):
                final_sentences.append(' '.join(current_group))
                current_group = []
        
        return final_sentences
    
    def _generate_cache_key(self, text: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        
        # í…ìŠ¤íŠ¸ì™€ ìŒì„± ì„¤ì •ì„ í¬í•¨í•œ í•´ì‹œ
        content = f"{text}_{self.voice_config['voice_id']}_{self.voice_config['model']}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def _get_from_cache(self, cache_key: str) -> Optional[bytes]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        
        if cache_key in self.response_cache:
            cache_entry = self.response_cache[cache_key]
            
            # TTL í™•ì¸
            if time.time() - cache_entry['timestamp'] < self.performance_config['cache_ttl']:
                return cache_entry['data']
            else:
                # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                del self.response_cache[cache_key]
        
        return None
    
    def _save_to_cache(self, cache_key: str, data: bytes):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        
        # ìºì‹œ í¬ê¸° ì œí•œ
        if len(self.response_cache) >= self.performance_config['max_cache_size']:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì‚­ì œ
            oldest_key = min(
                self.response_cache.keys(),
                key=lambda k: self.response_cache[k]['timestamp']
            )
            del self.response_cache[oldest_key]
        
        self.response_cache[cache_key] = {
            'data': data,
            'timestamp': time.time()
        }
    
    def _update_success_stats(self, start_time: float):
        """ì„±ê³µ í†µê³„ ì—…ë°ì´íŠ¸"""
        
        self.stats['successful_requests'] += 1
        
        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_time = time.time() - start_time
        self.response_times.append(response_time)
        
        # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
        if len(self.response_times) > self.max_response_history:
            self.response_times.pop(0)
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        if self.response_times:
            self.stats['avg_response_time'] = sum(self.response_times) / len(self.response_times)
        
        # ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°
        total_cache_requests = self.cache_stats['hits'] + self.cache_stats['misses']
        if total_cache_requests > 0:
            self.stats['cache_hit_rate'] = self.cache_stats['hits'] / total_cache_requests
    
    async def text_to_speech_file(self, text: str) -> bytes:
        """íŒŒì¼ ë°©ì‹ TTS (í˜¸í™˜ì„±ìš©)"""
        
        audio_chunks = []
        async for chunk in self.text_to_speech_stream(text):
            if chunk:
                audio_chunks.append(chunk)
        
        return b''.join(audio_chunks)
    
    async def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸ (ìµœì í™”)"""
        
        if not self.is_enabled:
            return False
        
        try:
            test_audio = await asyncio.wait_for(
                self.text_to_speech_file("í…ŒìŠ¤íŠ¸"),
                timeout=5.0
            )
            
            success = len(test_audio) > 0
            logger.info(f"TTS ì—°ê²° í…ŒìŠ¤íŠ¸: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}")
            return success
            
        except asyncio.TimeoutError:
            logger.error("TTS í…ŒìŠ¤íŠ¸ íƒ€ì„ì•„ì›ƒ")
            return False
        except Exception as e:
            logger.error(f"TTS í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        
        return {
            **self.stats,
            'cache_stats': self.cache_stats.copy(),
            'cache_size': len(self.response_cache),
            'is_enabled': self.is_enabled,
            'response_time_history': self.response_times.copy()
        }
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        
        cache_size = len(self.response_cache)
        self.response_cache.clear()
        self.cache_stats = {'hits': 0, 'misses': 0}
        
        logger.info(f"TTS ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {cache_size}ê°œ í•­ëª© ì‚­ì œ")
    
    def optimize_for_speed(self):
        """ì†ë„ ìµœì í™” ì„¤ì •"""
        
        self.performance_config.update({
            'max_chunk_size': 300,
            'timeout': 5.0,
            'max_cache_size': 100
        })
        
        self.voice_config['output_format'] = 'mp3_22050_32'  # ë‚®ì€ í’ˆì§ˆ, ë¹ ë¥¸ ì†ë„
        logger.info("ğŸš€ TTS ì†ë„ ìµœì í™” ëª¨ë“œ í™œì„±í™”")
    
    def optimize_for_quality(self):
        """í’ˆì§ˆ ìµœì í™” ì„¤ì •"""
        
        self.performance_config.update({
            'max_chunk_size': 800,
            'timeout': 15.0,
            'max_cache_size': 20
        })
        
        self.voice_config['output_format'] = 'mp3_44100_192'  # ë†’ì€ í’ˆì§ˆ
        logger.info("ğŸµ TTS í’ˆì§ˆ ìµœì í™” ëª¨ë“œ í™œì„±í™”")
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        
        try:
            logger.info("ğŸ§¹ TTS ì„œë¹„ìŠ¤ ì •ë¦¬ ì¤‘...")
            
            # ìºì‹œ ì •ë¦¬
            self.clear_cache()
            
            # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
            if self.thread_pool:
                self.thread_pool.shutdown(wait=True, timeout=3)
            
            # ìµœì¢… í†µê³„ ì¶œë ¥
            stats = self.get_performance_stats()
            logger.info("ğŸ“Š TTS ìµœì¢… í†µê³„:")
            logger.info(f"   ì´ ìš”ì²­: {stats['total_requests']}")
            logger.info(f"   ì„±ê³µë¥ : {stats['successful_requests']}/{stats['total_requests']}")
            logger.info(f"   ìºì‹œ íˆíŠ¸ìœ¨: {stats['cache_hit_rate']:.1%}")
            logger.info(f"   í‰ê·  ì‘ë‹µì‹œê°„: {stats['avg_response_time']:.3f}ì´ˆ")
            
            logger.info("âœ… TTS ì„œë¹„ìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"TTS ì •ë¦¬ ì˜¤ë¥˜: {e}")


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­ ë° ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
TTSService = OptimizedTTSService
tts_service = OptimizedTTSService()

# import asyncio
# import io
# import logging
# from typing import AsyncGenerator
# from elevenlabs import ElevenLabs, AsyncElevenLabs
# from config.settings import settings

# logger = logging.getLogger(__name__)

# class TTSService:
#     """
#     ElevenLabs TTS ì„œë¹„ìŠ¤ (ê³µì‹ Python SDK ê¸°ì¤€)
    
#     ì˜¬ë°”ë¥¸ SDK ë©”ì„œë“œ ì‚¬ìš©:
#     - client.text_to_speech.convert() - íŒŒì¼ ìƒì„±
#     - client.text_to_speech.stream() - ìŠ¤íŠ¸ë¦¬ë°
#     """
    
#     def __init__(self):
#         if not settings.ELEVENLABS_API_KEY:
#             logger.warning("ElevenLabs API key not found. TTS will be disabled.")
#             self.client = None
#             self.async_client = None
#         else:
#             self.client = ElevenLabs(api_key=settings.ELEVENLABS_API_KEY)
#             self.async_client = AsyncElevenLabs(api_key=settings.ELEVENLABS_API_KEY)
        
#         # ìŒì„± ì„¤ì •
#         self.voice_id = settings.TTS_VOICE_ID
#         self.model = settings.TTS_MODEL
    
#     async def text_to_speech_stream(self, text: str) -> AsyncGenerator[bytes, None]:
#         """
#         í…ìŠ¤íŠ¸ë¥¼ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜
#         ê³µì‹ SDK stream() ë©”ì„œë“œ ì‚¬ìš©
#         """
        
#         if not self.client:
#             logger.error("TTS client not initialized")
#             return
        
#         try:
#             logger.info(f"ğŸ”Š TTS ìŠ¤íŠ¸ë¦¼ ì‹œì‘: {text[:50]}...")
            
#             # ê³µì‹ SDK ìŠ¤íŠ¸ë¦¬ë° ë©”ì„œë“œ ì‚¬ìš© (ë™ê¸° ë²„ì „ì´ ë” ì•ˆì •ì )
#             def generate_stream():
#                 audio_stream = self.client.text_to_speech.stream(
#                     text=text,
#                     voice_id=self.voice_id,
#                     model_id=self.model,
#                     output_format="mp3_44100_128"
#                 )
                
#                 # ìŠ¤íŠ¸ë¦¼ì„ ìˆ˜ì§‘
#                 chunks = []
#                 for chunk in audio_stream:
#                     if isinstance(chunk, bytes):
#                         chunks.append(chunk)
                
#                 return b''.join(chunks)
            
#             # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
#             audio_data = await asyncio.to_thread(generate_stream)
            
#             if audio_data:
#                 # ì²­í¬ ë‹¨ìœ„ë¡œ yield
#                 chunk_size = 4096
#                 for i in range(0, len(audio_data), chunk_size):
#                     yield audio_data[i:i + chunk_size]
                
#                 logger.info(f"âœ… TTS ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ: {len(audio_data)} bytes")
#             else:
#                 logger.warning("âŒ TTS ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ì—†ìŒ")
#                 yield b''
                    
#         except Exception as e:
#             logger.error(f"TTS streaming error: {e}")
#             # í´ë°±ìœ¼ë¡œ convert ì‚¬ìš©
#             try:
#                 logger.info("ğŸ”„ convert ë©”ì„œë“œë¡œ í´ë°±...")
#                 audio_data = await self.text_to_speech_file(text)
#                 if audio_data:
#                     yield audio_data
#                 else:
#                     yield b''
#             except Exception as fallback_error:
#                 logger.error(f"í´ë°± ì˜¤ë¥˜: {fallback_error}")
#                 yield b''
    
#     async def text_to_speech_file(self, text: str) -> bytes:
#         """
#         í…ìŠ¤íŠ¸ë¥¼ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ë³€í™˜
#         ê³µì‹ SDK convert() ë©”ì„œë“œ ì‚¬ìš©
#         """
        
#         if not self.client:
#             return b''
        
#         try:
#             logger.info(f"ğŸ”Š TTS íŒŒì¼ ë³€í™˜: {text[:30]}...")
            
#             def generate_audio():
#                 # ê³µì‹ SDK convert ë©”ì„œë“œ ì‚¬ìš©
#                 audio_generator = self.client.text_to_speech.convert(
#                     text=text,
#                     voice_id=self.voice_id,
#                     model_id=self.model,
#                     output_format="mp3_44100_128"
#                 )
                
#                 # generatorë¥¼ bytesë¡œ ë³€í™˜
#                 chunks = []
#                 for chunk in audio_generator:
#                     if isinstance(chunk, bytes):
#                         chunks.append(chunk)
                
#                 return b''.join(chunks)
            
#             # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
#             audio_data = await asyncio.to_thread(generate_audio)
            
#             if audio_data:
#                 logger.info(f"âœ… TTS íŒŒì¼ ë³€í™˜ ì™„ë£Œ: {len(audio_data)} bytes")
#             else:
#                 logger.warning("âŒ TTS ë°ì´í„° ì—†ìŒ")
                
#             return audio_data
            
#         except Exception as e:
#             logger.error(f"TTS conversion error: {e}")
#             return b''
    
#     async def test_connection(self) -> bool:
#         """TTS ì„œë¹„ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        
#         if not self.client:
#             logger.warning("TTS í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
#             return False
        
#         try:
#             # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
#             test_audio = await self.text_to_speech_file("í…ŒìŠ¤íŠ¸")
#             success = len(test_audio) > 0
            
#             if success:
#                 logger.info("âœ… TTS ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
#                 logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ í¬ê¸°: {len(test_audio)} bytes")
#             else:
#                 logger.warning("âŒ TTS ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ë¹ˆ ì‘ë‹µ")
                
#             return success
            
#         except Exception as e:
#             logger.error(f"TTS test failed: {e}")
#             return False
    
#     def test_sync_basic(self) -> bool:
#         """ë™ê¸° ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (ë””ë²„ê¹…ìš©)"""
        
#         if not self.client:
#             return False
        
#         try:
#             logger.info("ğŸ§ª ë™ê¸° ê¸°ë³¸ í…ŒìŠ¤íŠ¸...")
            
#             # ê°€ì¥ ê¸°ë³¸ì ì¸ ì‚¬ìš©ë²•
#             audio_generator = self.client.text_to_speech.convert(
#                 text="í…ŒìŠ¤íŠ¸",
#                 voice_id=self.voice_id,
#                 model_id=self.model
#             )
            
#             # ì²« ë²ˆì§¸ ì²­í¬ë§Œ í™•ì¸
#             first_chunk = next(iter(audio_generator))
#             success = isinstance(first_chunk, bytes) and len(first_chunk) > 0
            
#             if success:
#                 logger.info("âœ… ë™ê¸° ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
#             else:
#                 logger.warning("âŒ ë™ê¸° ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            
#             return success
            
#         except Exception as e:
#             logger.error(f"ë™ê¸° ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
#             return False

# # ì „ì—­ TTS ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
# tts_service = TTSService()
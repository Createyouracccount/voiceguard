"""
VoiceGuard AI - ë‹¨ìˆœí™”ëœ ëª…í™•í•œ ì‹œìŠ¤í…œ
ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” AI ê¸°ëŠ¥ë§Œ ëª…í™•í•˜ê²Œ êµ¬í˜„
"""

import asyncio
import logging
import time
from datetime import datetime
from typing import Dict, Any, Optional
from enum import Enum

from core.llm_manager import llm_manager
from services.tts_service import tts_service
from services.audio_manager import audio_manager

logger = logging.getLogger(__name__)

class SimplifiedConversationManager:
    """ëª…í™•í•˜ê³  ë‹¨ìˆœí•œ AI ëŒ€í™” ê´€ë¦¬ì"""
    
    def __init__(self):
        # í•µì‹¬ AI ì»´í¬ë„ŒíŠ¸
        self.llm_manager = llm_manager  # Gemini ê¸°ë°˜ AI
        self.tts_service = tts_service
        self.audio_manager = audio_manager
        
        # ìƒíƒœ ê´€ë¦¬
        self.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.is_running = False
        self.stt_queue = asyncio.Queue(maxsize=10)
        
        # AI ì‚¬ìš© í˜„í™© ëª…í™•íˆ ì¶”ì 
        self.ai_usage = {
            'total_ai_calls': 0,
            'gemini_calls': 0,
            'successful_analyses': 0,
            'avg_ai_response_time': 0.0,
            'ai_cost_estimate': 0.0
        }
        
        # ë”ë¯¸ STT
        self.stt_service = self._create_test_stt()
        
        logger.info("ğŸ¤– Simplified AI System ì´ˆê¸°í™”")
        logger.info("   AI Engine: Google Gemini (LLM Manager)")
        logger.info("   Audio: ElevenLabs TTS + PyAudio")
        logger.info("   Analysis: ì§ì ‘ Gemini í˜¸ì¶œ")

    def _create_test_stt(self):
        """í…ŒìŠ¤íŠ¸ìš© STT"""
        class TestSTT:
            def __init__(self, callback):
                self.callback = callback
                self.is_running = False
            
            def start(self):
                self.is_running = True
                logger.info("ğŸ¤ í…ŒìŠ¤íŠ¸ STT ì‹œì‘")
                
                # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
                test_scenarios = [
                    "ì•ˆë…•í•˜ì„¸ìš”, ê¸ˆìœµê°ë…ì› ì¡°ì‚¬ê³¼ì…ë‹ˆë‹¤.",
                    "ê³ ê°ë‹˜ ê³„ì¢Œì—ì„œ ì˜ì‹¬ê±°ë˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "ì•ˆì „ì„ ìœ„í•´ ì„ì‹œ ê³„ì¢Œë¡œ ì´ì²´í•´ì£¼ì„¸ìš”.",
                    "ì§€ê¸ˆ ì¦‰ì‹œ ì²˜ë¦¬í•˜ì§€ ì•Šìœ¼ë©´ ê³„ì¢Œê°€ ë™ê²°ë©ë‹ˆë‹¤."
                ]
                
                async def simulate():
                    await asyncio.sleep(3)
                    for i, scenario in enumerate(test_scenarios):
                        if self.is_running:
                            logger.info(f"ğŸ­ ì‹œë‚˜ë¦¬ì˜¤ {i+1}: {scenario}")
                            self.callback(scenario)
                            await asyncio.sleep(8)  # 8ì´ˆ ê°„ê²©
                
                asyncio.create_task(simulate())
            
            def stop(self):
                self.is_running = False
        
        return TestSTT(self._on_speech_input)

    def _on_speech_input(self, text: str):
        """STT ì…ë ¥ ì²˜ë¦¬"""
        if text and text.strip():
            try:
                loop = asyncio.get_running_loop()
                loop.call_soon_threadsafe(self.stt_queue.put_nowait, text.strip())
            except Exception as e:
                logger.error(f"STT ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    async def start_conversation(self):
        """ëŒ€í™” ì‹œì‘"""
        
        logger.info("ğŸš€ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        
        # 1. Gemini ì—°ê²° í™•ì¸
        health_status = await self.llm_manager.health_check()
        active_models = [model for model, status in health_status.items() if status]
        
        if not active_models:
            logger.error("âŒ Gemini ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨")
            return False
        
        logger.info(f"âœ… Gemini ì—°ê²° ì„±ê³µ: {active_models}")
        
        # 2. ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ
        self.audio_manager.initialize_output()
        
        # 3. TTS í…ŒìŠ¤íŠ¸
        tts_ok = await self.tts_service.test_connection()
        logger.info(f"ğŸ”Š TTS ìƒíƒœ: {'OK' if tts_ok else 'FAIL'}")
        
        # 4. STT ì‹œì‘
        self.stt_service.start()
        
        self.is_running = True
        
        # ì‹œì‘ ë©”ì‹œì§€ (AI ì‚¬ìš© ëª…ì‹œ)
        await self._speak_with_ai_info(
            "ì•ˆë…•í•˜ì„¸ìš”! VoiceGuard AIì…ë‹ˆë‹¤. "
            "ì €ëŠ” Google Gemini ì¸ê³µì§€ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ë³´ì´ìŠ¤í”¼ì‹±ì„ ë¶„ì„í•©ë‹ˆë‹¤. "
            "ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ë§ì”€í•´ì£¼ì‹œë©´ AIê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ìœ„í—˜ë„ë¥¼ í‰ê°€í•´ë“œë¦½ë‹ˆë‹¤."
        )
        
        # ë©”ì¸ ë£¨í”„
        await self._main_conversation_loop()

    async def _main_conversation_loop(self):
        """ë©”ì¸ ëŒ€í™” ë£¨í”„"""
        
        while self.is_running:
            try:
                # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
                user_input = await asyncio.wait_for(
                    self.stt_queue.get(), 
                    timeout=2.0
                )
                
                if user_input:
                    await self._process_with_ai_analysis(user_input)
                    
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"ëŒ€í™” ë£¨í”„ ì˜¤ë¥˜: {e}")

    async def _process_with_ai_analysis(self, text: str):
        """AI ë¶„ì„ ì²˜ë¦¬ (ëª…í™•í•œ ë‹¨ê³„ë³„ ë¡œê¹…)"""
        
        ai_start_time = time.time()
        
        logger.info("=" * 60)
        logger.info(f"ğŸ¤– AI ë¶„ì„ ì‹œì‘")
        logger.info(f"ğŸ“ ì…ë ¥ í…ìŠ¤íŠ¸: {text}")
        logger.info(f"ğŸ§  AI ì—”ì§„: Google Gemini (via LLM Manager)")
        
        try:
            # === AI ë¶„ì„ ì‹¤í–‰ ===
            logger.info("âš¡ Gemini API í˜¸ì¶œ ì¤‘...")
            
            analysis_result = await self.llm_manager.analyze_scam_risk(
                text=text,
                context={
                    "session_id": self.session_id,
                    "timestamp": datetime.now().isoformat(),
                    "analysis_mode": "real_time_detection"
                }
            )
            
            ai_duration = time.time() - ai_start_time
            
            # === AI ê²°ê³¼ ë¡œê¹… ===
            logger.info(f"âœ… AI ë¶„ì„ ì™„ë£Œ ({ai_duration:.2f}ì´ˆ)")
            logger.info(f"ğŸ¯ ì‚¬ìš©ëœ ëª¨ë¸: {analysis_result.model_used}")
            logger.info(f"ğŸ’° ì˜ˆìƒ ë¹„ìš©: ${analysis_result.cost_estimate:.4f}")
            logger.info(f"ğŸ” ìœ„í—˜ë„: {analysis_result.metadata['risk_score']:.1%}")
            logger.info(f"ğŸ“Š ì‹ ë¢°ë„: {analysis_result.confidence:.1%}")
            logger.info(f"âš ï¸ ì‚¬ê¸° ìœ í˜•: {analysis_result.metadata.get('scam_type', 'unknown')}")
            
            # === í†µê³„ ì—…ë°ì´íŠ¸ ===
            self._update_ai_usage_stats(ai_duration, analysis_result)
            
            # === ì‚¬ìš©ì ì‘ë‹µ ìƒì„± ===
            response_text = self._create_clear_ai_response(analysis_result, ai_duration)
            
            # === ìŒì„± ì¶œë ¥ ===
            await self._speak_with_ai_info(response_text)
            
            logger.info("=" * 60)
            
        except Exception as e:
            logger.error(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            await self._speak_with_ai_info(
                "ì£„ì†¡í•©ë‹ˆë‹¤. AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. "
                "Gemini ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )

    def _create_clear_ai_response(self, analysis_result, processing_time: float) -> str:
        """ëª…í™•í•œ AI ë¶„ì„ ê²°ê³¼ ì‘ë‹µ ìƒì„±"""
        
        metadata = analysis_result.metadata
        risk_score = metadata.get('risk_score', 0.0)
        scam_type = metadata.get('scam_type', 'unknown')
        key_indicators = metadata.get('key_indicators', [])
        
        # AI ì‚¬ìš© ì •ë³´ ëª…ì‹œ
        response = f"""ğŸ¤– Google Gemini AI ë¶„ì„ ê²°ê³¼
(ì²˜ë¦¬ì‹œê°„: {processing_time:.1f}ì´ˆ, ëª¨ë¸: {analysis_result.model_used})

ğŸ“Š ìœ„í—˜ë„ í‰ê°€: {risk_score:.1%}
ğŸ¯ ì¶”ì • ì‚¬ê¸° ìœ í˜•: {scam_type}
ğŸ” AI ì‹ ë¢°ë„: {analysis_result.confidence:.1%}

ğŸ’¡ AIê°€ íƒì§€í•œ ìœ„í—˜ ìš”ì†Œ:"""

        # íƒì§€ëœ ì§€í‘œë“¤
        for i, indicator in enumerate(key_indicators[:5], 1):
            response += f"\n   {i}. {indicator}"

        # ìœ„í—˜ë„ë³„ ê¶Œì¥ì‚¬í•­
        if risk_score >= 0.8:
            response += """

ğŸš¨ AI íŒì •: ë§¤ìš° ë†’ì€ ìœ„í—˜
â€¢ ì¦‰ì‹œ í†µí™” ì¤‘ë‹¨ ê¶Œì¥
â€¢ 112 ë˜ëŠ” 1332 ì‹ ê³  í•„ìš”
â€¢ ì ˆëŒ€ ê°œì¸ì •ë³´ ì œê³µ ê¸ˆì§€"""

        elif risk_score >= 0.6:
            response += """

âš ï¸ AI íŒì •: ë†’ì€ ìœ„í—˜
â€¢ í†µí™” ì¤‘ë‹¨í•˜ê³  ì§ì ‘ í™•ì¸ í•„ìš”
â€¢ ìƒëŒ€ë°© ì‹ ì› ì¬í™•ì¸ ê¶Œì¥
â€¢ ê¸‰í•œ ê²°ì • í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤"""

        elif risk_score >= 0.4:
            response += """

ğŸ” AI íŒì •: ì£¼ì˜ í•„ìš”
â€¢ ìƒëŒ€ë°© ìš”êµ¬ì‚¬í•­ ì‹ ì¤‘íˆ ê²€í† 
â€¢ ê°œì¸ì •ë³´ ì œê³µ ì „ ì¬í™•ì¸
â€¢ ì˜ì‹¬ìŠ¤ëŸ¬ìš°ë©´ ê³µì‹ ê²½ë¡œ ì´ìš©"""

        else:
            response += """

âœ… AI íŒì •: ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì „
â€¢ í˜„ì¬ê¹Œì§€ëŠ” ìœ„í—˜ ìš”ì†Œ ì ìŒ
â€¢ ì—¬ì „íˆ ê°œì¸ì •ë³´ëŠ” ì‹ ì¤‘í•˜ê²Œ
â€¢ ì´ìƒí•œ ìš”êµ¬ ì‹œ ì¦‰ì‹œ í™•ì¸"""

        return response

    async def _speak_with_ai_info(self, text: str):
        """AI ì‚¬ìš© ì •ë³´ì™€ í•¨ê»˜ TTS ì¶œë ¥"""
        
        try:
            # TTS ì‹œì‘ ë¡œê¹…
            logger.info(f"ğŸ”Š TTS ì‹œì‘: {text[:50]}...")
            
            tts_start = time.time()
            audio_stream = self.tts_service.text_to_speech_stream(text)
            await self.audio_manager.play_audio_stream(audio_stream)
            
            tts_duration = time.time() - tts_start
            logger.info(f"âœ… TTS ì™„ë£Œ ({tts_duration:.1f}ì´ˆ)")
            
        except Exception as e:
            logger.error(f"TTS ì˜¤ë¥˜: {e}")

    def _update_ai_usage_stats(self, processing_time: float, analysis_result):
        """AI ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸"""
        
        self.ai_usage['total_ai_calls'] += 1
        self.ai_usage['gemini_calls'] += 1
        self.ai_usage['successful_analyses'] += 1
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„
        current_avg = self.ai_usage['avg_ai_response_time']
        call_count = self.ai_usage['total_ai_calls']
        self.ai_usage['avg_ai_response_time'] = (
            current_avg * (call_count - 1) + processing_time
        ) / call_count
        
        # ë¹„ìš© ëˆ„ì 
        self.ai_usage['ai_cost_estimate'] += analysis_result.cost_estimate
        
        # ì‹¤ì‹œê°„ í†µê³„ ë¡œê¹…
        logger.info(f"ğŸ“ˆ AI ì‚¬ìš© í†µê³„: ì´ {self.ai_usage['total_ai_calls']}íšŒ, "
                   f"í‰ê·  {self.ai_usage['avg_ai_response_time']:.2f}ì´ˆ, "
                   f"ì´ ë¹„ìš© ${self.ai_usage['ai_cost_estimate']:.4f}")

    def get_ai_usage_report(self) -> Dict[str, Any]:
        """AI ì‚¬ìš© í˜„í™© ë¦¬í¬íŠ¸"""
        
        # Gemini ëª¨ë¸ ìƒíƒœ
        gemini_stats = self.llm_manager.get_performance_stats()
        
        return {
            "session_info": {
                "session_id": self.session_id,
                "is_running": self.is_running,
                "start_time": getattr(self, 'start_time', 'unknown')
            },
            "ai_usage": self.ai_usage.copy(),
            "gemini_manager": {
                "active_models": list(self.llm_manager.models.keys()),
                "total_calls": gemini_stats.get('total_calls', 0),
                "total_cost": gemini_stats.get('total_cost', 0.0),
                "remaining_budget": gemini_stats.get('remaining_budget', 0.0)
            },
            "system_components": {
                "llm_manager": "âœ… Active (Gemini)",
                "tts_service": "âœ… Active (ElevenLabs)",
                "audio_manager": "âœ… Active (PyAudio)",
                "stt_service": "ğŸ§ª Test Mode"
            },
            "ai_effectiveness": {
                "success_rate": (
                    self.ai_usage['successful_analyses'] / 
                    max(1, self.ai_usage['total_ai_calls']) * 100
                ),
                "avg_response_time": self.ai_usage['avg_ai_response_time'],
                "cost_per_analysis": (
                    self.ai_usage['ai_cost_estimate'] / 
                    max(1, self.ai_usage['successful_analyses'])
                )
            }
        }

    async def show_ai_demo(self):
        """AI ì‹œìŠ¤í…œ ë°ëª¨"""
        
        logger.info("ğŸ­ AI ì‹œìŠ¤í…œ ë°ëª¨ ì‹œì‘")
        
        await self._speak_with_ai_info(
            "AI ì‹œìŠ¤í…œ ë°ëª¨ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. "
            "ê³§ ë³´ì´ìŠ¤í”¼ì‹± ì‹œë‚˜ë¦¬ì˜¤ë“¤ì´ ìë™ìœ¼ë¡œ ì…ë ¥ë˜ì–´ "
            "Gemini AIì˜ ì‹¤ì‹œê°„ ë¶„ì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        # ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
        demo_scenarios = [
            {
                "text": "ì•ˆë…•í•˜ì„¸ìš”, ê¸ˆìœµê°ë…ì›ì…ë‹ˆë‹¤. ê³ ê°ë‹˜ ê³„ì¢Œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "expected_risk": "high",
                "description": "ê¸°ê´€ì‚¬ì¹­ íŒ¨í„´"
            },
            {
                "text": "ì €ê¸ˆë¦¬ ëŒ€ì¶œ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì§€ê¸ˆ ì•±ë§Œ ì„¤ì¹˜í•˜ì‹œë©´ ë©ë‹ˆë‹¤.",
                "expected_risk": "medium",
                "description": "ëŒ€ì¶œì‚¬ê¸° + ì•…ì„±ì•±"
            },
            {
                "text": "ì•„ë“¤ì´ ì‚¬ê³ ë‚¬ì–´ìš”! ë³‘ì›ë¹„ê°€ ê¸‰í•´ìš”!",
                "expected_risk": "critical",
                "description": "ë‚©ì¹˜í˜‘ë°• íŒ¨í„´"
            }
        ]
        
        for i, scenario in enumerate(demo_scenarios, 1):
            await self._speak_with_ai_info(f"ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤ {i}: {scenario['description']}")
            await asyncio.sleep(2)
            
            logger.info(f"ğŸ­ ë°ëª¨ {i}: {scenario['text']}")
            await self._process_with_ai_analysis(scenario['text'])
            
            await asyncio.sleep(3)
        
        # ìµœì¢… ë¦¬í¬íŠ¸
        report = self.get_ai_usage_report()
        await self._speak_with_ai_info(
            f"ë°ëª¨ ì™„ë£Œ! ì´ {report['ai_usage']['total_ai_calls']}íšŒ AI ë¶„ì„, "
            f"í‰ê·  {report['ai_effectiveness']['avg_response_time']:.1f}ì´ˆ ì†Œìš”ë˜ì—ˆìŠµë‹ˆë‹¤."
        )

    async def cleanup(self):
        """ì‹œìŠ¤í…œ ì •ë¦¬"""
        
        logger.info("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...")
        
        self.is_running = False
        
        try:
            # STT ì •ë¦¬
            if hasattr(self.stt_service, 'stop'):
                self.stt_service.stop()
            
            # ì˜¤ë””ì˜¤ ì •ë¦¬
            self.audio_manager.cleanup()
            
            # ìµœì¢… AI ì‚¬ìš© ë¦¬í¬íŠ¸
            final_report = self.get_ai_usage_report()
            
            logger.info("ğŸ“Š ìµœì¢… AI ì‚¬ìš© ë¦¬í¬íŠ¸:")
            logger.info(f"   ì´ AI í˜¸ì¶œ: {final_report['ai_usage']['total_ai_calls']}")
            logger.info(f"   ì„±ê³µë¥ : {final_report['ai_effectiveness']['success_rate']:.1f}%")
            logger.info(f"   ì´ ë¹„ìš©: ${final_report['ai_usage']['ai_cost_estimate']:.4f}")
            logger.info(f"   í‰ê·  ì‘ë‹µì‹œê°„: {final_report['ai_effectiveness']['avg_response_time']:.2f}ì´ˆ")
            
            logger.info("âœ… ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_ai_system():
    """AI ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ¤– VoiceGuard AI System Test")
    print("=" * 50)
    
    manager = SimplifiedConversationManager()
    
    try:
        # AI ë°ëª¨ ì‹¤í–‰
        await manager.show_ai_demo()
        
        # ìƒíƒœ ë¦¬í¬íŠ¸
        report = manager.get_ai_usage_report()
        print("\nğŸ“Š AI ì‹œìŠ¤í…œ ìƒíƒœ:")
        for component, status in report['system_components'].items():
            print(f"   {component}: {status}")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        await manager.cleanup()

if __name__ == "__main__":
    asyncio.run(test_ai_system())
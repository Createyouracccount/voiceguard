"""
VoiceGuard AI - ë³´ì´ìŠ¤í”¼ì‹± ë¶„ì„ ì—”ì§„
í…ìŠ¤íŠ¸ ê¸°ë°˜ ë³´ì´ìŠ¤í”¼ì‹± íƒì§€ ë° ë¶„ì„
"""

import asyncio
import logging
import time
from typing import Dict, Any, List, Optional
from datetime import datetime

from config.settings import scam_config, detection_thresholds
from config.prompts.detection_prompts import DETECTION_PROMPTS

logger = logging.getLogger(__name__)

class VoicePhishingAnalyzer:
    """ë³´ì´ìŠ¤í”¼ì‹± ë¶„ì„ ì—”ì§„"""
    
    def __init__(self, llm_manager):
        self.llm_manager = llm_manager
        
        # ë¶„ì„ í†µê³„
        self.stats = {
            'total_analyses': 0,
            'high_risk_detections': 0,
            'avg_analysis_time': 0.0,
            'pattern_matches': {}
        }
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ìŠ¤í¬ë¦¬ë‹
        self.quick_patterns = self._build_quick_patterns()
        
        logger.info("ë³´ì´ìŠ¤í”¼ì‹± ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _build_quick_patterns(self) -> Dict[str, Any]:
        """ë¹ ë¥¸ íŒ¨í„´ ë§¤ì¹­ì„ ìœ„í•œ í‚¤ì›Œë“œ ì‚¬ì „"""
        
        patterns = {
            'critical_keywords': [
                'ë‚©ì¹˜', 'ìœ ê´´', 'ì£½ëŠ”ë‹¤', 'ì²´í¬ì˜ì¥', 'ê³„ì¢Œë™ê²°', 'ì‘ê¸‰ì‹¤'
            ],
            'high_risk_keywords': [
                'ê¸ˆìœµê°ë…ì›', 'ê²€ì°°ì²­', 'ê²½ì°°ì„œ', 'ìˆ˜ì‚¬', 'ì¡°ì‚¬', 'ë²”ì£„', 'í”¼ì˜ì'
            ],
            'medium_risk_keywords': [
                'ëŒ€ì¶œ', 'ì €ê¸ˆë¦¬', 'ì •ë¶€ì§€ì›ê¸ˆ', 'í™˜ê¸‰', 'ë‹¹ì²¨', 'ë§Œë‚˜ì„œ', 'ì§ì ‘'
            ],
            'financial_keywords': [
                'ê³„ì¢Œë²ˆí˜¸', 'ë¹„ë°€ë²ˆí˜¸', 'ì†¡ê¸ˆ', 'ì´ì²´', 'í˜„ê¸ˆ', 'ì¹´ë“œë²ˆí˜¸'
            ],
            'app_keywords': [
                'ì•±ì„¤ì¹˜', 'ë‹¤ìš´ë¡œë“œ', 'ê¶Œí•œ', 'í—ˆìš©', 'ì—…ë°ì´íŠ¸', 'ì¸ì¦'
            ]
        }
        
        return patterns
    
    async def analyze_text(self, text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ë¶„ì„ ë©”ì¸ ë©”ì„œë“œ"""
        
        start_time = time.time()
        context = context or {}
        
        try:
            # 1. ë¹ ë¥¸ í‚¤ì›Œë“œ ìŠ¤í¬ë¦¬ë‹
            quick_result = self._quick_keyword_analysis(text)
            
            # 2. ìœ„í—˜ë„ê°€ ë‚®ìœ¼ë©´ ë¹ ë¥¸ ì¢…ë£Œ
            if quick_result['risk_score'] < 0.2:
                return self._create_low_risk_result(text, quick_result, start_time)
            
            # 3. LLM ê¸°ë°˜ ì •ë°€ ë¶„ì„
            llm_result = await self._llm_analysis(text, context, quick_result)
            
            # 4. ê²°ê³¼ í†µí•©
            final_result = self._integrate_results(quick_result, llm_result, start_time)
            
            # 5. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(final_result)
            
            return final_result
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return self._create_error_result(text, str(e), start_time)
    
    def _quick_keyword_analysis(self, text: str) -> Dict[str, Any]:
        """ë¹ ë¥¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„"""
        
        text_lower = text.lower()
        risk_score = 0.0
        detected_patterns = []
        scam_indicators = []
        
        # ê° íŒ¨í„´ë³„ ì ìˆ˜ ê³„ì‚°
        for pattern_type, keywords in self.quick_patterns.items():
            matches = [kw for kw in keywords if kw in text_lower]
            
            if matches:
                detected_patterns.append(pattern_type)
                scam_indicators.extend(matches)
                
                # íŒ¨í„´ë³„ ê°€ì¤‘ì¹˜
                if pattern_type == 'critical_keywords':
                    risk_score += len(matches) * 0.4
                elif pattern_type == 'high_risk_keywords':
                    risk_score += len(matches) * 0.3
                elif pattern_type == 'medium_risk_keywords':
                    risk_score += len(matches) * 0.2
                elif pattern_type == 'financial_keywords':
                    risk_score += len(matches) * 0.25
                elif pattern_type == 'app_keywords':
                    risk_score += len(matches) * 0.2
        
        # ì—¬ëŸ¬ íŒ¨í„´ì´ ë™ì‹œì— ë‚˜íƒ€ë‚˜ë©´ ìœ„í—˜ë„ ì¦ê°€
        if len(detected_patterns) >= 2:
            risk_score *= 1.3
        
        # ìµœì¢… ì ìˆ˜ ì •ê·œí™”
        risk_score = min(risk_score, 1.0)
        
        return {
            'risk_score': risk_score,
            'detected_patterns': detected_patterns,
            'scam_indicators': list(set(scam_indicators)),
            'method': 'keyword_analysis'
        }
    
    async def _llm_analysis(self, text: str, context: Dict[str, Any], quick_result: Dict[str, Any]) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ ì •ë°€ ë¶„ì„"""
        
        try:
            # ë¶„ì„ ê²°ê³¼ ìš”ì²­
            analysis_result = await self.llm_manager.analyze_scam_risk(
                text=text,
                context={
                    **context,
                    'preliminary_risk': quick_result['risk_score'],
                    'detected_indicators': quick_result['scam_indicators']
                }
            )
            
            # ê²°ê³¼ íŒŒì‹±
            metadata = analysis_result.metadata
            
            return {
                'risk_score': metadata.get('risk_score', 0.5),
                'scam_type': metadata.get('scam_type', 'unknown'),
                'confidence': analysis_result.confidence,
                'key_indicators': metadata.get('key_indicators', []),
                'immediate_action': metadata.get('immediate_action', False),
                'reasoning': analysis_result.content,
                'method': 'llm_analysis'
            }
            
        except Exception as e:
            logger.error(f"LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
            # í´ë°±: í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©
            return {
                'risk_score': quick_result['risk_score'],
                'scam_type': self._estimate_scam_type(quick_result['scam_indicators']),
                'confidence': 0.6,
                'key_indicators': quick_result['scam_indicators'],
                'immediate_action': quick_result['risk_score'] >= 0.8,
                'reasoning': 'LLM ë¶„ì„ ì‹¤íŒ¨ë¡œ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©',
                'method': 'fallback_analysis'
            }
    
    def _estimate_scam_type(self, indicators: List[str]) -> str:
        """í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ê¸° ìœ í˜• ì¶”ì •"""
        
        type_keywords = {
            'ê¸°ê´€ì‚¬ì¹­': ['ê¸ˆìœµê°ë…ì›', 'ê²€ì°°ì²­', 'ê²½ì°°ì„œ', 'ìˆ˜ì‚¬', 'ì¡°ì‚¬'],
            'ë‚©ì¹˜í˜‘ë°•': ['ë‚©ì¹˜', 'ìœ ê´´', 'ì‘ê¸‰ì‹¤', 'ì‚¬ê³ ', 'ì£½ëŠ”ë‹¤'],
            'ëŒ€ì¶œì‚¬ê¸°': ['ëŒ€ì¶œ', 'ì €ê¸ˆë¦¬', 'ë¬´ë‹´ë³´', 'ì •ë¶€ì§€ì›'],
            'ì•…ì„±ì•±': ['ì•±ì„¤ì¹˜', 'ë‹¤ìš´ë¡œë“œ', 'ê¶Œí•œ', 'í—ˆìš©'],
            'ëŒ€ë©´í¸ì·¨': ['ë§Œë‚˜ì„œ', 'ì§ì ‘', 'í˜„ì¥', 'ì¹´í˜', 'í˜„ê¸ˆ']
        }
        
        max_matches = 0
        estimated_type = 'unknown'
        
        for scam_type, keywords in type_keywords.items():
            matches = sum(1 for kw in keywords if kw in indicators)
            if matches > max_matches:
                max_matches = matches
                estimated_type = scam_type
        
        return estimated_type
    
    def _integrate_results(self, quick_result: Dict[str, Any], llm_result: Dict[str, Any], start_time: float) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ í†µí•©"""
        
        # ìœ„í—˜ë„ ì ìˆ˜ í†µí•© (LLM ê²°ê³¼ ìš°ì„ , í‚¤ì›Œë“œ ê²°ê³¼ë¡œ ë³´ì •)
        final_risk_score = llm_result['risk_score']
        
        # í‚¤ì›Œë“œ ë¶„ì„ì—ì„œ ë§¤ìš° ë†’ì€ ìœ„í—˜ë„ê°€ ë‚˜ì™”ë‹¤ë©´ ìƒí–¥ ì¡°ì •
        if quick_result['risk_score'] >= 0.8 and final_risk_score < 0.8:
            final_risk_score = max(final_risk_score, 0.7)
        
        # ì£¼ìš” ì§€í‘œ í†µí•©
        all_indicators = list(set(
            quick_result['scam_indicators'] + 
            llm_result.get('key_indicators', [])
        ))
        
        # ìœ„í—˜ ë ˆë²¨ ê²°ì •
        if final_risk_score >= detection_thresholds.critical_risk:
            risk_level = "ë§¤ìš° ìœ„í—˜"
        elif final_risk_score >= detection_thresholds.high_risk:
            risk_level = "ìœ„í—˜"
        elif final_risk_score >= detection_thresholds.medium_risk:
            risk_level = "ì£¼ì˜"
        else:
            risk_level = "ë‚®ìŒ"
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendation = self._generate_recommendation(final_risk_score, llm_result['scam_type'])
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = time.time() - start_time
        
        return {
            'risk_score': final_risk_score,
            'risk_level': risk_level,
            'scam_type': llm_result['scam_type'],
            'confidence': llm_result['confidence'],
            'key_indicators': all_indicators[:10],  # ìƒìœ„ 10ê°œë§Œ
            'immediate_action': llm_result['immediate_action'],
            'recommendation': recommendation,
            'reasoning': llm_result['reasoning'],
            'processing_time': processing_time,
            'analysis_methods': [quick_result['method'], llm_result['method']],
            'timestamp': datetime.now().isoformat()
        }
    
    def _generate_recommendation(self, risk_score: float, scam_type: str) -> str:
        """ìœ„í—˜ë„ì™€ ì‚¬ê¸° ìœ í˜•ì— ë”°ë¥¸ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        base_recommendations = {
            'ê¸°ê´€ì‚¬ì¹­': "í•´ë‹¹ ê¸°ê´€ì— ì§ì ‘ ì „í™”í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”.",
            'ë‚©ì¹˜í˜‘ë°•': "ì¹¨ì°©í•˜ê²Œ ê°€ì¡±ì—ê²Œ ì§ì ‘ ì—°ë½í•˜ê³  112ì— ì‹ ê³ í•˜ì„¸ìš”.",
            'ëŒ€ì¶œì‚¬ê¸°': "ê¸ˆìœµê°ë…ì› í™ˆí˜ì´ì§€ì—ì„œ ë“±ë¡ì—…ì²´ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.",
            'ì•…ì„±ì•±': "ê³µì‹ ì•±ìŠ¤í† ì–´ ì™¸ì—ëŠ” ì•±ì„ ì„¤ì¹˜í•˜ì§€ ë§ˆì„¸ìš”.",
            'ëŒ€ë©´í¸ì·¨': "ì ˆëŒ€ ì§ì ‘ ë§Œë‚˜ì§€ ë§ê³  ê²½ì°°ì— ì‹ ê³ í•˜ì„¸ìš”."
        }
        
        recommendation = base_recommendations.get(scam_type, "ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í†µí™”ëŠ” ì¦‰ì‹œ ëŠê³  í™•ì¸í•˜ì„¸ìš”.")
        
        # ìœ„í—˜ë„ì— ë”°ë¥¸ ì¶”ê°€ ê¶Œì¥ì‚¬í•­
        if risk_score >= 0.8:
            recommendation = f"ğŸš¨ ì¦‰ì‹œ í†µí™”ë¥¼ ëŠìœ¼ì„¸ìš”! {recommendation}"
        elif risk_score >= 0.6:
            recommendation = f"âš ï¸ ë§¤ìš° ì£¼ì˜í•˜ì„¸ìš”. {recommendation}"
        elif risk_score >= 0.4:
            recommendation = f"ğŸ” {recommendation}"
        
        return recommendation
    
    def _create_low_risk_result(self, text: str, quick_result: Dict[str, Any], start_time: float) -> Dict[str, Any]:
        """ì €ìœ„í—˜ ê²°ê³¼ ìƒì„±"""
        
        processing_time = time.time() - start_time
        
        return {
            'risk_score': quick_result['risk_score'],
            'risk_level': "ë‚®ìŒ",
            'scam_type': "í•´ë‹¹ì—†ìŒ",
            'confidence': 0.8,
            'key_indicators': quick_result['scam_indicators'],
            'immediate_action': False,
            'recommendation': "í˜„ì¬ê¹Œì§€ëŠ” ì•ˆì „í•œ í†µí™”ë¡œ ë³´ì´ì§€ë§Œ ê³„ì† ì£¼ì˜í•˜ì„¸ìš”.",
            'reasoning': "í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ìœ„í—˜ ìš”ì†Œê°€ ì ê²Œ ë°œê²¬ë¨",
            'processing_time': processing_time,
            'analysis_methods': [quick_result['method']],
            'timestamp': datetime.now().isoformat()
        }
    
    def _create_error_result(self, text: str, error_msg: str, start_time: float) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ê²°ê³¼ ìƒì„±"""
        
        processing_time = time.time() - start_time
        
        return {
            'risk_score': 0.5,  # ì¤‘ê°„ ìœ„í—˜ë„ë¡œ ì„¤ì • (ì•ˆì „ì„ ìœ„í•´)
            'risk_level': "ì£¼ì˜",
            'scam_type': "ë¶„ì„ì‹¤íŒ¨",
            'confidence': 0.3,
            'key_indicators': ["ì‹œìŠ¤í…œ_ì˜¤ë¥˜"],
            'immediate_action': False,
            'recommendation': "ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í†µí™”ëŠ” ëŠê³  ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”.",
            'reasoning': f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_msg}",
            'processing_time': processing_time,
            'analysis_methods': ["error_handling"],
            'timestamp': datetime.now().isoformat(),
            'error': True
        }
    
    def _update_stats(self, result: Dict[str, Any]):
        """ë¶„ì„ í†µê³„ ì—…ë°ì´íŠ¸"""
        
        self.stats['total_analyses'] += 1
        
        # ê³ ìœ„í—˜ íƒì§€ ì¹´ìš´íŠ¸
        if result['risk_score'] >= detection_thresholds.high_risk:
            self.stats['high_risk_detections'] += 1
        
        # í‰ê·  ë¶„ì„ ì‹œê°„ ì—…ë°ì´íŠ¸
        current_avg = self.stats['avg_analysis_time']
        total_count = self.stats['total_analyses']
        new_time = result['processing_time']
        
        self.stats['avg_analysis_time'] = (current_avg * (total_count - 1) + new_time) / total_count
        
        # íŒ¨í„´ ë§¤ì¹­ í†µê³„
        scam_type = result['scam_type']
        if scam_type != "í•´ë‹¹ì—†ìŒ" and scam_type != "ë¶„ì„ì‹¤íŒ¨":
            self.stats['pattern_matches'][scam_type] = self.stats['pattern_matches'].get(scam_type, 0) + 1
    
    def get_analysis_stats(self) -> Dict[str, Any]:
        """ë¶„ì„ í†µê³„ ì¡°íšŒ"""
        
        detection_rate = 0.0
        if self.stats['total_analyses'] > 0:
            detection_rate = self.stats['high_risk_detections'] / self.stats['total_analyses']
        
        return {
            **self.stats,
            'detection_rate': detection_rate,
            'performance': {
                'avg_analysis_time': f"{self.stats['avg_analysis_time']:.3f}ì´ˆ",
                'total_analyses': self.stats['total_analyses'],
                'success_rate': "ë¶„ì„ ì„±ê³µë¥  ê³„ì‚° í•„ìš”"  # í–¥í›„ êµ¬í˜„
            }
        }
    
    async def batch_analyze(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ë¶„ì„ (ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë™ì‹œ ì²˜ë¦¬)"""
        
        tasks = []
        for text in texts:
            task = self.analyze_text(text)
            tasks.append(task)
        
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì˜ˆì™¸ ì²˜ë¦¬
            processed_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"ë°°ì¹˜ ë¶„ì„ {i}ë²ˆì§¸ ì‹¤íŒ¨: {result}")
                    processed_results.append(self._create_error_result(texts[i], str(result), 0))
                else:
                    processed_results.append(result)
            
            return processed_results
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return [self._create_error_result(text, str(e), 0) for text in texts]
    
    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        
        self.stats = {
            'total_analyses': 0,
            'high_risk_detections': 0,
            'avg_analysis_time': 0.0,
            'pattern_matches': {}
        }
        
        logger.info("ë¶„ì„ ì—”ì§„ í†µê³„ ì´ˆê¸°í™”ë¨")